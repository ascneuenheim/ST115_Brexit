{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e78a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4c0f0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:36: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:36: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:148: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2018 = pd.read_csv(output_csv_path_2018, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:148: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2018 = pd.read_csv(output_csv_path_2018, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:217: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2018\n",
      "Home Fee: 9250\n",
      "Overseas Fee: 19152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:260: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2019 = pd.read_csv(output_csv_path_2019, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:260: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2019 = pd.read_csv(output_csv_path_2019, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 234: expected 5 fields, saw 8\n",
      "Skipping line 235: expected 5 fields, saw 8\n",
      "Skipping line 236: expected 5 fields, saw 8\n",
      "Skipping line 237: expected 5 fields, saw 8\n",
      "Skipping line 238: expected 5 fields, saw 8\n",
      "Skipping line 239: expected 5 fields, saw 8\n",
      "Skipping line 240: expected 5 fields, saw 9\n",
      "Skipping line 241: expected 5 fields, saw 9\n",
      "Skipping line 242: expected 5 fields, saw 9\n",
      "Skipping line 243: expected 5 fields, saw 9\n",
      "Skipping line 244: expected 5 fields, saw 9\n",
      "Skipping line 245: expected 5 fields, saw 9\n",
      "Skipping line 246: expected 5 fields, saw 9\n",
      "Skipping line 247: expected 5 fields, saw 9\n",
      "Skipping line 248: expected 5 fields, saw 9\n",
      "Skipping line 249: expected 5 fields, saw 9\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:331: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2019\n",
      "Home Fee: 9250\n",
      "Overseas Fee: 19920\n",
      "Year: 2020\n",
      "Home Fee: 9250\n",
      "Overseas Fee: 21570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:374: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2020 = pd.read_csv(output_csv_path_2020, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:374: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2020 = pd.read_csv(output_csv_path_2020, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 244: expected 5 fields, saw 8\n",
      "Skipping line 245: expected 5 fields, saw 8\n",
      "Skipping line 246: expected 5 fields, saw 8\n",
      "Skipping line 247: expected 5 fields, saw 8\n",
      "Skipping line 248: expected 5 fields, saw 8\n",
      "Skipping line 249: expected 5 fields, saw 8\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "Skipping line 262: expected 5 fields, saw 9\n",
      "Skipping line 263: expected 5 fields, saw 9\n",
      "Skipping line 264: expected 5 fields, saw 9\n",
      "Skipping line 265: expected 5 fields, saw 9\n",
      "Skipping line 266: expected 5 fields, saw 9\n",
      "Skipping line 267: expected 5 fields, saw 9\n",
      "Skipping line 268: expected 5 fields, saw 9\n",
      "Skipping line 269: expected 5 fields, saw 9\n",
      "Skipping line 270: expected 5 fields, saw 9\n",
      "Skipping line 271: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_69954/2049031719.py:443: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24120</td>\n",
       "      <td>24372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19607</td>\n",
       "      <td>21054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17587</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>25578</td>\n",
       "      <td>25767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Government</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13208</td>\n",
       "      <td>20312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15792</td>\n",
       "      <td>22584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16800</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17292</td>\n",
       "      <td>20844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14784</td>\n",
       "      <td>21576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>22479</td>\n",
       "      <td>22491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19476</td>\n",
       "      <td>23280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18336</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16560</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15376</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21180</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Social Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13538</td>\n",
       "      <td>20178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17320</td>\n",
       "      <td>22224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14784</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18336</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18409</td>\n",
       "      <td>21684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>25080</td>\n",
       "      <td>25344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20848</td>\n",
       "      <td>21796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19936</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26599</td>\n",
       "      <td>26797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16392</td>\n",
       "      <td>23448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17480</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17988</td>\n",
       "      <td>21672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15384</td>\n",
       "      <td>22440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23670</td>\n",
       "      <td>23756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19062</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17220</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20363</td>\n",
       "      <td>20954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Social Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18048</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19062</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18922</td>\n",
       "      <td>22326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26082</td>\n",
       "      <td>26358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21917</td>\n",
       "      <td>22870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19192</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>27663</td>\n",
       "      <td>27870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17512</td>\n",
       "      <td>24832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18708</td>\n",
       "      <td>22536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16008</td>\n",
       "      <td>23328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24575</td>\n",
       "      <td>24826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21072</td>\n",
       "      <td>25176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19830</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17916</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17280</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>22294</td>\n",
       "      <td>23570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23400</td>\n",
       "      <td>26320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16640</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19830</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19194</td>\n",
       "      <td>22994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28080</td>\n",
       "      <td>28464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23179</td>\n",
       "      <td>24134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19952</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28969</td>\n",
       "      <td>29185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18160</td>\n",
       "      <td>25768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19452</td>\n",
       "      <td>23436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16656</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28441</td>\n",
       "      <td>28703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21912</td>\n",
       "      <td>26184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18624</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17968</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21987</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24336</td>\n",
       "      <td>27376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17296</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19470</td>\n",
       "      <td>23732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                               Accounting  PG Taught      24120   \n",
       "1                         Economic History  PG Taught      13008   \n",
       "2                                Economics  PG Taught      19607   \n",
       "3                       European Institute  PG Taught      17587   \n",
       "4                                  Finance  PG Taught      25578   \n",
       "5                           Gender Studies  PG Taught      13008   \n",
       "6                Geography And Environment  PG Taught      13008   \n",
       "7                               Government  PG Taught      13208   \n",
       "8                            Health Policy  PG Taught      15792   \n",
       "9                International Development  PG Taught      16800   \n",
       "10                 International Relations  PG Taught      17292   \n",
       "11                              Law School  PG Taught      14784   \n",
       "12                              Management  PG Taught      22479   \n",
       "13                             Mathematics  PG Taught      19476   \n",
       "14                 Media And Communication  PG Taught      18336   \n",
       "15  Philosophy Logic And Scientific Method  PG Taught      16560   \n",
       "16   Psychological And Behavioural Science  PG Taught      15376   \n",
       "17                 School of Public Policy  PG Taught      21180   \n",
       "18                           Social Policy  PG Taught      13538   \n",
       "19                               Sociology  PG Taught      13008   \n",
       "20                              Statistics  PG Taught      17320   \n",
       "21                            Anthropology  PG Taught      14784   \n",
       "22                   International History  PG Taught      13008   \n",
       "23                 Media And Communication  PG Taught      18336   \n",
       "24                         International..  PG Taught      18409   \n",
       "25                              Accounting  PG Taught      25080   \n",
       "26                        Economic History  PG Taught      13536   \n",
       "27                               Economics  PG Taught      20848   \n",
       "28                      European Institute  PG Taught      19936   \n",
       "29                                 Finance  PG Taught      26599   \n",
       "30                          Gender Studies  PG Taught      13536   \n",
       "31               Geography And Environment  PG Taught      13536   \n",
       "32                           Health Policy  PG Taught      16392   \n",
       "33               International Development  PG Taught      17480   \n",
       "34                 International Relations  PG Taught      17988   \n",
       "35                              Law School  PG Taught      15384   \n",
       "36                              Management  PG Taught      23670   \n",
       "37                             Mathematics  PG Taught      20256   \n",
       "38                 Media And Communication  PG Taught      19062   \n",
       "39  Philosophy Logic And Scientific Method  PG Taught      17220   \n",
       "40   Psychological And Behavioural Science  PG Taught      15992   \n",
       "41                 School of Public Policy  PG Taught      20363   \n",
       "42                           Social Policy  PG Taught      18048   \n",
       "43                               Sociology  PG Taught      13536   \n",
       "44                              Statistics  PG Taught      20256   \n",
       "45                            Anthropology  PG Taught      15992   \n",
       "46                   International History  PG Taught      13536   \n",
       "47                 Media And Communication  PG Taught      19062   \n",
       "48                         International..  PG Taught      18922   \n",
       "49                              Accounting  PG Taught      26082   \n",
       "50                        Economic History  PG Taught      14088   \n",
       "51                               Economics  PG Taught      21917   \n",
       "52                      European Institute  PG Taught      19192   \n",
       "53                                 Finance  PG Taught      27663   \n",
       "54                          Gender Studies  PG Taught      14088   \n",
       "55               Geography And Environment  PG Taught      14088   \n",
       "56                           Health Policy  PG Taught      17512   \n",
       "57               International Development  PG Taught      14088   \n",
       "58                 International Relations  PG Taught      18708   \n",
       "59                              Law School  PG Taught      16008   \n",
       "60                              Management  PG Taught      24575   \n",
       "61                             Mathematics  PG Taught      21072   \n",
       "62                 Media And Communication  PG Taught      19830   \n",
       "63  Philosophy Logic And Scientific Method  PG Taught      17916   \n",
       "64   Psychological And Behavioural Science  PG Taught      17280   \n",
       "65                 School of Public Policy  PG Taught      22294   \n",
       "66                               Sociology  PG Taught      14088   \n",
       "67                              Statistics  PG Taught      23400   \n",
       "68                            Anthropology  PG Taught      16640   \n",
       "69                   International History  PG Taught      14088   \n",
       "70                 Media And Communication  PG Taught      19830   \n",
       "71                         International..  PG Taught      19194   \n",
       "72                              Accounting  PG Taught      28080   \n",
       "73                        Economic History  PG Taught      14640   \n",
       "74                               Economics  PG Taught      23179   \n",
       "75                      European Institute  PG Taught      19952   \n",
       "76                                 Finance  PG Taught      28969   \n",
       "77                          Gender Studies  PG Taught      14640   \n",
       "78               Geography And Environment  PG Taught      14640   \n",
       "79                           Health Policy  PG Taught      18160   \n",
       "80               International Development  PG Taught      14640   \n",
       "81                 International Relations  PG Taught      19452   \n",
       "82                              Law School  PG Taught      16656   \n",
       "83                              Management  PG Taught      28441   \n",
       "84                             Mathematics  PG Taught      21912   \n",
       "85                 Media And Communication  PG Taught      20616   \n",
       "86  Philosophy Logic And Scientific Method  PG Taught      18624   \n",
       "87   Psychological And Behavioural Science  PG Taught      17968   \n",
       "88                 School of Public Policy  PG Taught      21987   \n",
       "89                               Sociology  PG Taught      14640   \n",
       "90                              Statistics  PG Taught      24336   \n",
       "91                            Anthropology  PG Taught      17296   \n",
       "92                   International History  PG Taught      14640   \n",
       "93                 Media And Communication  PG Taught      20616   \n",
       "94                         International..  PG Taught      19470   \n",
       "\n",
       "    Overseas fees  \n",
       "0           24372  \n",
       "1           20112  \n",
       "2           21054  \n",
       "3           20112  \n",
       "4           25767  \n",
       "5           20112  \n",
       "6           20112  \n",
       "7           20312  \n",
       "8           22584  \n",
       "9           20112  \n",
       "10          20844  \n",
       "11          21576  \n",
       "12          22491  \n",
       "13          23280  \n",
       "14          20112  \n",
       "15          20112  \n",
       "16          20112  \n",
       "17          20112  \n",
       "18          20178  \n",
       "19          20112  \n",
       "20          22224  \n",
       "21          20112  \n",
       "22          20112  \n",
       "23          20112  \n",
       "24          21684  \n",
       "25          25344  \n",
       "26          20904  \n",
       "27          21796  \n",
       "28          20904  \n",
       "29          26797  \n",
       "30          20904  \n",
       "31          20904  \n",
       "32          23448  \n",
       "33          20904  \n",
       "34          21672  \n",
       "35          22440  \n",
       "36          23756  \n",
       "37          24204  \n",
       "38          20904  \n",
       "39          20904  \n",
       "40          20904  \n",
       "41          20954  \n",
       "42          20904  \n",
       "43          20904  \n",
       "44          24204  \n",
       "45          20904  \n",
       "46          20904  \n",
       "47          20904  \n",
       "48          22326  \n",
       "49          26358  \n",
       "50          21744  \n",
       "51          22870  \n",
       "52          21744  \n",
       "53          27870  \n",
       "54          21744  \n",
       "55          21744  \n",
       "56          24832  \n",
       "57          21744  \n",
       "58          22536  \n",
       "59          23328  \n",
       "60          24826  \n",
       "61          25176  \n",
       "62          21744  \n",
       "63          21744  \n",
       "64          21744  \n",
       "65          23570  \n",
       "66          21744  \n",
       "67          26320  \n",
       "68          21744  \n",
       "69          21744  \n",
       "70          21744  \n",
       "71          22994  \n",
       "72          28464  \n",
       "73          22608  \n",
       "74          24134  \n",
       "75          22608  \n",
       "76          29185  \n",
       "77          22608  \n",
       "78          22608  \n",
       "79          25768  \n",
       "80          22608  \n",
       "81          23436  \n",
       "82          24264  \n",
       "83          28703  \n",
       "84          26184  \n",
       "85          22608  \n",
       "86          22608  \n",
       "87          22608  \n",
       "88          24264  \n",
       "89          22608  \n",
       "90          27376  \n",
       "91          22608  \n",
       "92          22608  \n",
       "93          22608  \n",
       "94          23732  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract tables from a PDF and write to CSV\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "\n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Process each PDF and extract data\n",
    "\n",
    "# 2017\n",
    "pdf_path_2017 = 'Data/2017-18-Fees-Table.pdf'\n",
    "output_csv_path_2017 = 'Data/2017_Fees'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path_2017, output_csv_path_2017)\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path_2017 = 'Data/2017_Fees.csv'\n",
    "csv_path_2017 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2017 = pd.read_csv(csv_path_2017)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df_2017['Dept_Program'] = data_df_2017['Department'] + \" \" + data_df_2017['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs_2017 = data_df_2017['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed_2017 = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs_2017 = []\n",
    "for combo in unique_dept_programs_2017:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "\n",
    "            # Save mapping\n",
    "            original_to_transformed_2017[transformed_department] = original_department\n",
    "            processed_dept_programs_2017.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df_2017 = pd.DataFrame(processed_dept_programs_2017, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df_2017.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2017(dept_program):\n",
    "    matches = data_df_one_2017[data_df_one_2017.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "\n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df_2017[['Home fees', 'Overseas fees']] = processed_df_2017['Department'].apply(find_matching_data_2017)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df_2017.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df_2017['Home fees'] = processed_df_2017['Home fees'].astype(int)\n",
    "processed_df_2017['Overseas fees'] = processed_df_2017['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df_2017['Department'] = processed_df_2017['Department'].map(original_to_transformed_2017)\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx_2017 = data_df_one_2017.index[data_df_one_2017.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2017:\n",
    "    target_idx_2017 = idx_2017[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one_2017.iloc[target_idx_2017 - 1, 0]:\n",
    "        year_match_2017 = re.search(r'\\b(\\d{4})\\b', data_df_one_2017.iloc[target_idx_2017, 0])\n",
    "        year_2017 = year_match_2017.group(0) if year_match_2017 else \"Unknown\"\n",
    "        home_fee_match_2017 = re.search(r'£(\\d{4})', data_df_one_2017.iloc[target_idx_2017, 1].replace(',', ''))\n",
    "        overseas_fee_match_2017 = re.search(r'£(\\d{5})', data_df_one_2017.iloc[target_idx_2017, 2].replace(',', ''))\n",
    "        home_fee_2017 = int(home_fee_match_2017.group(1)) if home_fee_match_2017 else None\n",
    "        overseas_fee_2017 = int(overseas_fee_match_2017.group(1)) if overseas_fee_match_2017 else None\n",
    "        print(\"Year:\", year_2017)\n",
    "        print(\"Home Fee:\", home_fee_2017)\n",
    "        print(\"Overseas Fee:\", overseas_fee_2017)\n",
    "\n",
    "# 2018\n",
    "pdf_path_2018 = 'Data/2018-19-Fees-Table.pdf'\n",
    "output_csv_path_2018 = 'Data/2018_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path_2018, output_csv_path_2018)\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path_2018 = 'Data/2018_Fees.csv'\n",
    "csv_path_2018 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one_2018 = pd.read_csv(output_csv_path_2018, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2018 = pd.read_csv(csv_path_2018)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df_2018['Dept_Program'] = data_df_2018['Department'] + \" \" + data_df_2018['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs_2018 = data_df_2018['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed_2018 = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs_2018 = []\n",
    "for combo in unique_dept_programs_2018:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "\n",
    "            # Save mapping\n",
    "            original_to_transformed_2018[transformed_department] = original_department\n",
    "            processed_dept_programs_2018.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df_2018 = pd.DataFrame(processed_dept_programs_2018, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df_2018.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2018(dept_program):\n",
    "    matches = data_df_one_2018[data_df_one_2018.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "\n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df_2018[['Home fees', 'Overseas fees']] = processed_df_2018['Department'].apply(find_matching_data_2018)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df_2018.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df_2018['Home fees'] = processed_df_2018['Home fees'].astype(int)\n",
    "processed_df_2018['Overseas fees'] = processed_df_2018['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df_2018['Department'] = processed_df_2018['Department'].map(original_to_transformed_2018)\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx_2018 = data_df_one_2018.index[data_df_one_2018.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2018:\n",
    "    target_idx_2018 = idx_2018[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one_2018.iloc[target_idx_2018 - 1, 0]:\n",
    "        year_match_2018 = re.search(r'\\b(\\d{4})\\b', data_df_one_2018.iloc[target_idx_2018, 0])\n",
    "        year_2018 = year_match_2018.group(0) if year_match_2018 else \"Unknown\"\n",
    "        home_fee_match_2018 = re.search(r'£(\\d{4})', data_df_one_2018.iloc[target_idx_2018, 1].replace(',', ''))\n",
    "        overseas_fee_match_2018 = re.search(r'£(\\d{5})', data_df_one_2018.iloc[target_idx_2018, 2].replace(',', ''))\n",
    "        home_fee_2018 = int(home_fee_match_2018.group(1)) if home_fee_match_2018 else None\n",
    "        overseas_fee_2018 = int(overseas_fee_match_2018.group(1)) if overseas_fee_match_2018 else None\n",
    "        print(\"Year:\", year_2018)\n",
    "        print(\"Home Fee:\", home_fee_2018)\n",
    "        print(\"Overseas Fee:\", overseas_fee_2018)\n",
    "\n",
    "# 2019\n",
    "pdf_path_2019 = 'Data/2019-Table-of-Fees.pdf'\n",
    "output_csv_path_2019 = 'Data/2019_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path_2019, output_csv_path_2019)\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path_2019 = 'Data/2019_Fees.csv'\n",
    "csv_path_2019 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one_2019 = pd.read_csv(output_csv_path_2019, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2019 = pd.read_csv(csv_path_2019)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df_2019['Dept_Program'] = data_df_2019['Department'] + \" \" + data_df_2019['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs_2019 = data_df_2019['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed_2019 = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs_2019 = []\n",
    "for combo in unique_dept_programs_2019:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "\n",
    "            # Save mapping\n",
    "            original_to_transformed_2019[transformed_department] = original_department\n",
    "            processed_dept_programs_2019.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df_2019 = pd.DataFrame(processed_dept_programs_2019, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df_2019.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2019(dept_program):\n",
    "    matches = data_df_one_2019[data_df_one_2019.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "\n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df_2019[['Home fees', 'Overseas fees']] = processed_df_2019['Department'].apply(find_matching_data_2019)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df_2019.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df_2019['Home fees'] = processed_df_2019['Home fees'].astype(int)\n",
    "processed_df_2019['Overseas fees'] = processed_df_2019['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df_2019['Department'] = processed_df_2019['Department'].map(original_to_transformed_2019)\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx_2019 = data_df_one_2019.index[data_df_one_2019.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2019:\n",
    "    target_idx_2019 = idx_2019[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one_2019.iloc[target_idx_2019 - 1, 0]:\n",
    "        year_match_2019 = re.search(r'\\b(\\d{4})\\b', data_df_one_2019.iloc[target_idx_2019, 0])\n",
    "        year_2019 = year_match_2019.group(0) if year_match_2019 else \"Unknown\"\n",
    "        home_fee_match_2019 = re.search(r'£(\\d{4})', data_df_one_2019.iloc[target_idx_2019, 1].replace(',', ''))\n",
    "        overseas_fee_match_2019 = re.search(r'£(\\d{5})', data_df_one_2019.iloc[target_idx_2019, 2].replace(',', ''))\n",
    "        home_fee_2019 = int(home_fee_match_2019.group(1)) if home_fee_match_2019 else None\n",
    "        overseas_fee_2019 = int(overseas_fee_match_2019.group(1)) if overseas_fee_match_2019 else None\n",
    "        print(\"Year:\", year_2019)\n",
    "        print(\"Home Fee:\", home_fee_2019)\n",
    "        print(\"Overseas Fee:\", overseas_fee_2019)\n",
    "\n",
    "# 2020\n",
    "pdf_path_2020 = \"Data/2020-Table-of-Fees-25Jun20.pdf\"\n",
    "output_csv_path_2020 = 'Data/2020_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path_2020, output_csv_path_2020)\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path_2020 = 'Data/2020_Fees.csv'\n",
    "csv_path_2020 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'\n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one_2020 = pd.read_csv(output_csv_path_2020, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2020 = pd.read_csv(csv_path_2020)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df_2020['Dept_Program'] = data_df_2020['Department'] + \" \" + data_df_2020['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs_2020 = data_df_2020['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed_2020 = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs_2020 = []\n",
    "for combo in unique_dept_programs_2020:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "\n",
    "            # Save mapping\n",
    "            original_to_transformed_2020[transformed_department] = original_department\n",
    "            processed_dept_programs_2020.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df_2020 = pd.DataFrame(processed_dept_programs_2020, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df_2020.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2020(dept_program):\n",
    "    matches = data_df_one_2020[data_df_one_2020.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "\n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df_2020[['Home fees', 'Overseas fees']] = processed_df_2020['Department'].apply(find_matching_data_2020)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df_2020.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df_2020['Home fees'] = processed_df_2020['Home fees'].astype(int)\n",
    "processed_df_2020['Overseas fees'] = processed_df_2020['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df_2020['Department'] = processed_df_2020['Department'].map(original_to_transformed_2020)\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx_2020 = data_df_one_2020.index[data_df_one_2020.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2020:\n",
    "    target_idx_2020 = idx_2020[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one_2020.iloc[target_idx_2020 - 1, 0]:\n",
    "        year_match_2020 = re.search(r'\\b(\\d{4})\\b', data_df_one_2020.iloc[target_idx_2020, 0])\n",
    "        year_2020 = year_match_2020.group(0) if year_match_2020 else \"Unknown\"\n",
    "        home_fee_match_2020 = re.search(r'£(\\d{4})', data_df_one_2020.iloc[target_idx_2020, 1].replace(',', ''))\n",
    "        overseas_fee_match_2020 = re.search(r'£(\\d{5})', data_df_one_2020.iloc[target_idx_2020, 2].replace(',', ''))\n",
    "        home_fee_2020 = int(home_fee_match_2020.group(1)) if home_fee_match_2020 else None\n",
    "        overseas_fee_2020 = int(overseas_fee_match_2020.group(1)) if overseas_fee_match_2020 else None\n",
    "        print(\"Year:\", year_2020)\n",
    "        print(\"Home Fee:\", home_fee_2020)\n",
    "        print(\"Overseas Fee:\", overseas_fee_2020)\n",
    "\n",
    "# Merge dataframes from different years\n",
    "frames = [processed_df_2017, processed_df_2018, processed_df_2019, processed_df_2020]\n",
    "result_df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display the combined dataframe\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7c159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8849cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f3dfd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
