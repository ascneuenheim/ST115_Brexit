{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff69a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def setup_driver(download_dir):\n",
    "    \"\"\"Sets up the WebDriver for Chrome.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # Disable PDF viewer to automatically download PDF files\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": download_dir,\n",
    "        \"download.prompt_for_download\": False,  # Disable download prompt\n",
    "        \"plugins.always_open_pdf_externally\": True  # It will not show PDF directly in chrome\n",
    "    })\n",
    "    # Set up Chrome driver\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def download_pdfs_by_class(base_url, class_name, download_dir):\n",
    "    driver = setup_driver(download_dir)\n",
    "    driver.get(base_url)\n",
    "\n",
    "    # Wait for the page to load\n",
    "    time.sleep(1)  # Increase or decrease based on your internet speed\n",
    "\n",
    "    # Find all elements with the specified class and download the linked files\n",
    "    links = driver.find_elements(By.CLASS_NAME, class_name)\n",
    "    for link in links:\n",
    "        href = link.get_attribute('href')\n",
    "        if href and href.endswith('.pdf'):\n",
    "            # Open the link in a new tab\n",
    "            driver.execute_script(f\"window.open('{href}');\")\n",
    "            time.sleep(1)  # Adjust time for page load as necessary\n",
    "            # Switch back to the main window\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Base URL of the page containing the links\n",
    "base_url = 'https://info.lse.ac.uk/staff/divisions/Planning-Division/Table-of-Fees'\n",
    "# Class shared by PDF links\n",
    "class_name = 'sys_21'\n",
    "# Path to the download directory\n",
    "download_dir = r'C:\\Users\\Philip Gerner\\Documents\\GitHub\\Project\\Data\\TuitionFees'\n",
    "\n",
    "download_pdfs_by_class(base_url, class_name, download_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6def1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/3464139488.py:34: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/3464139488.py:34: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 244: expected 5 fields, saw 8\n",
      "Skipping line 245: expected 5 fields, saw 8\n",
      "Skipping line 246: expected 5 fields, saw 8\n",
      "Skipping line 247: expected 5 fields, saw 8\n",
      "Skipping line 248: expected 5 fields, saw 8\n",
      "Skipping line 249: expected 5 fields, saw 8\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "Skipping line 262: expected 5 fields, saw 9\n",
      "Skipping line 263: expected 5 fields, saw 9\n",
      "Skipping line 264: expected 5 fields, saw 9\n",
      "Skipping line 265: expected 5 fields, saw 9\n",
      "Skipping line 266: expected 5 fields, saw 9\n",
      "Skipping line 267: expected 5 fields, saw 9\n",
      "Skipping line 268: expected 5 fields, saw 9\n",
      "Skipping line 269: expected 5 fields, saw 9\n",
      "Skipping line 270: expected 5 fields, saw 9\n",
      "Skipping line 271: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/3464139488.py:103: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 2020</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>21570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28080</td>\n",
       "      <td>28464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23179</td>\n",
       "      <td>24134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19952</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28969</td>\n",
       "      <td>29185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18160</td>\n",
       "      <td>25768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19452</td>\n",
       "      <td>23436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16656</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28441</td>\n",
       "      <td>28703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21912</td>\n",
       "      <td>26184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18624</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17968</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21987</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24336</td>\n",
       "      <td>27376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17296</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19470</td>\n",
       "      <td>23732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                                 All 2020  UG Degree       9250   \n",
       "1                               Accounting  PG Taught      28080   \n",
       "2                         Economic History  PG Taught      14640   \n",
       "3                                Economics  PG Taught      23179   \n",
       "4                       European Institute  PG Taught      19952   \n",
       "5                                  Finance  PG Taught      28969   \n",
       "6                           Gender Studies  PG Taught      14640   \n",
       "7                Geography And Environment  PG Taught      14640   \n",
       "8                            Health Policy  PG Taught      18160   \n",
       "9                International Development  PG Taught      14640   \n",
       "10                 International Relations  PG Taught      19452   \n",
       "11                              Law School  PG Taught      16656   \n",
       "12                              Management  PG Taught      28441   \n",
       "13                             Mathematics  PG Taught      21912   \n",
       "14                 Media And Communication  PG Taught      20616   \n",
       "15  Philosophy Logic And Scientific Method  PG Taught      18624   \n",
       "16   Psychological And Behavioural Science  PG Taught      17968   \n",
       "17                 School of Public Policy  PG Taught      21987   \n",
       "18                               Sociology  PG Taught      14640   \n",
       "19                              Statistics  PG Taught      24336   \n",
       "20                            Anthropology  PG Taught      17296   \n",
       "21                   International History  PG Taught      14640   \n",
       "22                 Media And Communication  PG Taught      20616   \n",
       "23                         International..  PG Taught      19470   \n",
       "\n",
       "    Overseas fees  \n",
       "0           21570  \n",
       "1           28464  \n",
       "2           22608  \n",
       "3           24134  \n",
       "4           22608  \n",
       "5           29185  \n",
       "6           22608  \n",
       "7           22608  \n",
       "8           25768  \n",
       "9           22608  \n",
       "10          23436  \n",
       "11          24264  \n",
       "12          28703  \n",
       "13          26184  \n",
       "14          22608  \n",
       "15          22608  \n",
       "16          22608  \n",
       "17          24264  \n",
       "18          22608  \n",
       "19          27376  \n",
       "20          22608  \n",
       "21          22608  \n",
       "22          22608  \n",
       "23          23732  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2020\n",
    "\n",
    "import pdfplumber\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path = 'Data/2020-Table-of-Fees-25Jun20.pdf'\n",
    "output_csv_path = 'Data/2020_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path, output_csv_path)\n",
    "\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path = 'Data/2020_Fees.csv'  \n",
    "csv_path = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df['Dept_Program'] = data_df['Department'] + \" \" + data_df['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs = data_df['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs = []\n",
    "for combo in unique_dept_programs:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed[transformed_department] = original_department\n",
    "            processed_dept_programs.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df = pd.DataFrame(processed_dept_programs, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data(dept_program):\n",
    "    matches = data_df_one[data_df_one.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df[['Home fees', 'Overseas fees']] = processed_df['Department'].apply(find_matching_data)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df['Home fees'] = processed_df['Home fees'].astype(int)\n",
    "processed_df['Overseas fees'] = processed_df['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df['Department'] = processed_df['Department'].map(original_to_transformed)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx = data_df_one.index[data_df_one.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx:\n",
    "    target_idx = idx[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one.iloc[target_idx - 1, 0]:\n",
    "        year_match = re.search(r'\\b(\\d{4})\\b', data_df_one.iloc[target_idx, 0])\n",
    "        year = year_match.group(0) if year_match else \"Unknown\"\n",
    "        home_fee_match = re.search(r'£(\\d{4})', data_df_one.iloc[target_idx, 1].replace(',', ''))\n",
    "        overseas_fee_match = re.search(r'£(\\d{5})', data_df_one.iloc[target_idx, 2].replace(',', ''))\n",
    "        home_fee = int(home_fee_match.group(1)) if home_fee_match else None\n",
    "        overseas_fee = int(overseas_fee_match.group(1)) if overseas_fee_match else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row = pd.DataFrame({\n",
    "    'Department': [f\"All {year}\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee],\n",
    "    'Overseas fees': [overseas_fee]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df = pd.concat([additional_row, processed_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d69df80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e166c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed73d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eca0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6823006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/980795836.py:31: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/980795836.py:31: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/980795836.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 2018</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>19152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>25080</td>\n",
       "      <td>25344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20848</td>\n",
       "      <td>21796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19936</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26599</td>\n",
       "      <td>26797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16392</td>\n",
       "      <td>23448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17480</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17988</td>\n",
       "      <td>21672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15384</td>\n",
       "      <td>22440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23670</td>\n",
       "      <td>23756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19062</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17220</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20363</td>\n",
       "      <td>20954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Social Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18048</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19062</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18922</td>\n",
       "      <td>22326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                                 All 2018  UG Degree       9250   \n",
       "1                               Accounting  PG Taught      25080   \n",
       "2                         Economic History  PG Taught      13536   \n",
       "3                                Economics  PG Taught      20848   \n",
       "4                       European Institute  PG Taught      19936   \n",
       "5                                  Finance  PG Taught      26599   \n",
       "6                           Gender Studies  PG Taught      13536   \n",
       "7                Geography And Environment  PG Taught      13536   \n",
       "8                            Health Policy  PG Taught      16392   \n",
       "9                International Development  PG Taught      17480   \n",
       "10                 International Relations  PG Taught      17988   \n",
       "11                              Law School  PG Taught      15384   \n",
       "12                              Management  PG Taught      23670   \n",
       "13                             Mathematics  PG Taught      20256   \n",
       "14                 Media And Communication  PG Taught      19062   \n",
       "15  Philosophy Logic And Scientific Method  PG Taught      17220   \n",
       "16   Psychological And Behavioural Science  PG Taught      15992   \n",
       "17                 School of Public Policy  PG Taught      20363   \n",
       "18                           Social Policy  PG Taught      18048   \n",
       "19                               Sociology  PG Taught      13536   \n",
       "20                              Statistics  PG Taught      20256   \n",
       "21                            Anthropology  PG Taught      15992   \n",
       "22                   International History  PG Taught      13536   \n",
       "23                 Media And Communication  PG Taught      19062   \n",
       "24                         International..  PG Taught      18922   \n",
       "\n",
       "    Overseas fees  \n",
       "0           19152  \n",
       "1           25344  \n",
       "2           20904  \n",
       "3           21796  \n",
       "4           20904  \n",
       "5           26797  \n",
       "6           20904  \n",
       "7           20904  \n",
       "8           23448  \n",
       "9           20904  \n",
       "10          21672  \n",
       "11          22440  \n",
       "12          23756  \n",
       "13          24204  \n",
       "14          20904  \n",
       "15          20904  \n",
       "16          20904  \n",
       "17          20954  \n",
       "18          20904  \n",
       "19          20904  \n",
       "20          24204  \n",
       "21          20904  \n",
       "22          20904  \n",
       "23          20904  \n",
       "24          22326  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2018\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path = 'Data/2018-19-Fees-Table.pdf'\n",
    "output_csv_path = 'Data/2018_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path, output_csv_path)\n",
    "\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path = 'Data/2018_Fees.csv'  \n",
    "csv_path = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df['Dept_Program'] = data_df['Department'] + \" \" + data_df['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs = data_df['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs = []\n",
    "for combo in unique_dept_programs:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed[transformed_department] = original_department\n",
    "            processed_dept_programs.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df = pd.DataFrame(processed_dept_programs, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data(dept_program):\n",
    "    matches = data_df_one[data_df_one.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df[['Home fees', 'Overseas fees']] = processed_df['Department'].apply(find_matching_data)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df['Home fees'] = processed_df['Home fees'].astype(int)\n",
    "processed_df['Overseas fees'] = processed_df['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df['Department'] = processed_df['Department'].map(original_to_transformed)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx = data_df_one.index[data_df_one.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx:\n",
    "    target_idx = idx[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one.iloc[target_idx - 1, 0]:\n",
    "        year_match = re.search(r'\\b(\\d{4})\\b', data_df_one.iloc[target_idx, 0])\n",
    "        year = year_match.group(0) if year_match else \"Unknown\"\n",
    "        home_fee_match = re.search(r'£(\\d{4})', data_df_one.iloc[target_idx, 1].replace(',', ''))\n",
    "        overseas_fee_match = re.search(r'£(\\d{5})', data_df_one.iloc[target_idx, 2].replace(',', ''))\n",
    "        home_fee = int(home_fee_match.group(1)) if home_fee_match else None\n",
    "        overseas_fee = int(overseas_fee_match.group(1)) if overseas_fee_match else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row = pd.DataFrame({\n",
    "    'Department': [f\"All {year}\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee],\n",
    "    'Overseas fees': [overseas_fee]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df = pd.concat([additional_row, processed_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346bd336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25be78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b045a997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/65106076.py:31: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/65106076.py:31: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 234: expected 5 fields, saw 8\n",
      "Skipping line 235: expected 5 fields, saw 8\n",
      "Skipping line 236: expected 5 fields, saw 8\n",
      "Skipping line 237: expected 5 fields, saw 8\n",
      "Skipping line 238: expected 5 fields, saw 8\n",
      "Skipping line 239: expected 5 fields, saw 8\n",
      "Skipping line 240: expected 5 fields, saw 9\n",
      "Skipping line 241: expected 5 fields, saw 9\n",
      "Skipping line 242: expected 5 fields, saw 9\n",
      "Skipping line 243: expected 5 fields, saw 9\n",
      "Skipping line 244: expected 5 fields, saw 9\n",
      "Skipping line 245: expected 5 fields, saw 9\n",
      "Skipping line 246: expected 5 fields, saw 9\n",
      "Skipping line 247: expected 5 fields, saw 9\n",
      "Skipping line 248: expected 5 fields, saw 9\n",
      "Skipping line 249: expected 5 fields, saw 9\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/65106076.py:100: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 2019</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>19920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26082</td>\n",
       "      <td>26358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21917</td>\n",
       "      <td>22870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19192</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>27663</td>\n",
       "      <td>27870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17512</td>\n",
       "      <td>24832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18708</td>\n",
       "      <td>22536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16008</td>\n",
       "      <td>23328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24575</td>\n",
       "      <td>24826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21072</td>\n",
       "      <td>25176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19830</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17916</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17280</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>22294</td>\n",
       "      <td>23570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23400</td>\n",
       "      <td>26320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16640</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19830</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19194</td>\n",
       "      <td>22994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                                 All 2019  UG Degree       9250   \n",
       "1                               Accounting  PG Taught      26082   \n",
       "2                         Economic History  PG Taught      14088   \n",
       "3                                Economics  PG Taught      21917   \n",
       "4                       European Institute  PG Taught      19192   \n",
       "5                                  Finance  PG Taught      27663   \n",
       "6                           Gender Studies  PG Taught      14088   \n",
       "7                Geography And Environment  PG Taught      14088   \n",
       "8                            Health Policy  PG Taught      17512   \n",
       "9                International Development  PG Taught      14088   \n",
       "10                 International Relations  PG Taught      18708   \n",
       "11                              Law School  PG Taught      16008   \n",
       "12                              Management  PG Taught      24575   \n",
       "13                             Mathematics  PG Taught      21072   \n",
       "14                 Media And Communication  PG Taught      19830   \n",
       "15  Philosophy Logic And Scientific Method  PG Taught      17916   \n",
       "16   Psychological And Behavioural Science  PG Taught      17280   \n",
       "17                 School of Public Policy  PG Taught      22294   \n",
       "18                               Sociology  PG Taught      14088   \n",
       "19                              Statistics  PG Taught      23400   \n",
       "20                            Anthropology  PG Taught      16640   \n",
       "21                   International History  PG Taught      14088   \n",
       "22                 Media And Communication  PG Taught      19830   \n",
       "23                         International..  PG Taught      19194   \n",
       "\n",
       "    Overseas fees  \n",
       "0           19920  \n",
       "1           26358  \n",
       "2           21744  \n",
       "3           22870  \n",
       "4           21744  \n",
       "5           27870  \n",
       "6           21744  \n",
       "7           21744  \n",
       "8           24832  \n",
       "9           21744  \n",
       "10          22536  \n",
       "11          23328  \n",
       "12          24826  \n",
       "13          25176  \n",
       "14          21744  \n",
       "15          21744  \n",
       "16          21744  \n",
       "17          23570  \n",
       "18          21744  \n",
       "19          26320  \n",
       "20          21744  \n",
       "21          21744  \n",
       "22          21744  \n",
       "23          22994  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2018\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path = 'Data/2019-Table-of-Fees.pdf'\n",
    "output_csv_path = 'Data/2019_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path, output_csv_path)\n",
    "\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path = 'Data/2019_Fees.csv'  \n",
    "csv_path = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df['Dept_Program'] = data_df['Department'] + \" \" + data_df['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs = data_df['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs = []\n",
    "for combo in unique_dept_programs:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed[transformed_department] = original_department\n",
    "            processed_dept_programs.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df = pd.DataFrame(processed_dept_programs, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data(dept_program):\n",
    "    matches = data_df_one[data_df_one.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df[['Home fees', 'Overseas fees']] = processed_df['Department'].apply(find_matching_data)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df['Home fees'] = processed_df['Home fees'].astype(int)\n",
    "processed_df['Overseas fees'] = processed_df['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df['Department'] = processed_df['Department'].map(original_to_transformed)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx = data_df_one.index[data_df_one.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx:\n",
    "    target_idx = idx[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one.iloc[target_idx - 1, 0]:\n",
    "        year_match = re.search(r'\\b(\\d{4})\\b', data_df_one.iloc[target_idx, 0])\n",
    "        year = year_match.group(0) if year_match else \"Unknown\"\n",
    "        home_fee_match = re.search(r'£(\\d{4})', data_df_one.iloc[target_idx, 1].replace(',', ''))\n",
    "        overseas_fee_match = re.search(r'£(\\d{5})', data_df_one.iloc[target_idx, 2].replace(',', ''))\n",
    "        home_fee = int(home_fee_match.group(1)) if home_fee_match else None\n",
    "        overseas_fee = int(overseas_fee_match.group(1)) if overseas_fee_match else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row = pd.DataFrame({\n",
    "    'Department': [f\"All {year}\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee],\n",
    "    'Overseas fees': [overseas_fee]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df = pd.concat([additional_row, processed_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5146e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673cbf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff608253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0689754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/410907778.py:31: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_68270/410907778.py:31: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 2019</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>19920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24120</td>\n",
       "      <td>24372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19607</td>\n",
       "      <td>21054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17587</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>25578</td>\n",
       "      <td>25767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Government</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13208</td>\n",
       "      <td>20312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15792</td>\n",
       "      <td>22584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16800</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17292</td>\n",
       "      <td>20844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14784</td>\n",
       "      <td>21576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>22479</td>\n",
       "      <td>22491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19476</td>\n",
       "      <td>23280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18336</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16560</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15376</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21180</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Social Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13538</td>\n",
       "      <td>20178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17320</td>\n",
       "      <td>22224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14784</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13008</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18336</td>\n",
       "      <td>20112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18409</td>\n",
       "      <td>21684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                                 All 2019  UG Degree       9250   \n",
       "1                               Accounting  PG Taught      24120   \n",
       "2                         Economic History  PG Taught      13008   \n",
       "3                                Economics  PG Taught      19607   \n",
       "4                       European Institute  PG Taught      17587   \n",
       "5                                  Finance  PG Taught      25578   \n",
       "6                           Gender Studies  PG Taught      13008   \n",
       "7                Geography And Environment  PG Taught      13008   \n",
       "8                               Government  PG Taught      13208   \n",
       "9                            Health Policy  PG Taught      15792   \n",
       "10               International Development  PG Taught      16800   \n",
       "11                 International Relations  PG Taught      17292   \n",
       "12                              Law School  PG Taught      14784   \n",
       "13                              Management  PG Taught      22479   \n",
       "14                             Mathematics  PG Taught      19476   \n",
       "15                 Media And Communication  PG Taught      18336   \n",
       "16  Philosophy Logic And Scientific Method  PG Taught      16560   \n",
       "17   Psychological And Behavioural Science  PG Taught      15376   \n",
       "18                 School of Public Policy  PG Taught      21180   \n",
       "19                           Social Policy  PG Taught      13538   \n",
       "20                               Sociology  PG Taught      13008   \n",
       "21                              Statistics  PG Taught      17320   \n",
       "22                            Anthropology  PG Taught      14784   \n",
       "23                   International History  PG Taught      13008   \n",
       "24                 Media And Communication  PG Taught      18336   \n",
       "25                         International..  PG Taught      18409   \n",
       "\n",
       "    Overseas fees  \n",
       "0           19920  \n",
       "1           24372  \n",
       "2           20112  \n",
       "3           21054  \n",
       "4           20112  \n",
       "5           25767  \n",
       "6           20112  \n",
       "7           20112  \n",
       "8           20312  \n",
       "9           22584  \n",
       "10          20112  \n",
       "11          20844  \n",
       "12          21576  \n",
       "13          22491  \n",
       "14          23280  \n",
       "15          20112  \n",
       "16          20112  \n",
       "17          20112  \n",
       "18          20112  \n",
       "19          20178  \n",
       "20          20112  \n",
       "21          22224  \n",
       "22          20112  \n",
       "23          20112  \n",
       "24          20112  \n",
       "25          21684  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2018\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path = 'Data/2017-18-Fees-Table.pdf'\n",
    "output_csv_path = 'Data/2017_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path, output_csv_path)\n",
    "\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path = 'Data/2017_Fees.csv'  \n",
    "csv_path = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df['Dept_Program'] = data_df['Department'] + \" \" + data_df['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs = data_df['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs = []\n",
    "for combo in unique_dept_programs:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed[transformed_department] = original_department\n",
    "            processed_dept_programs.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df = pd.DataFrame(processed_dept_programs, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data(dept_program):\n",
    "    matches = data_df_one[data_df_one.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df[['Home fees', 'Overseas fees']] = processed_df['Department'].apply(find_matching_data)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df['Home fees'] = processed_df['Home fees'].astype(int)\n",
    "processed_df['Overseas fees'] = processed_df['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df['Department'] = processed_df['Department'].map(original_to_transformed)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx = data_df_one.index[data_df_one.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx:\n",
    "    target_idx = idx[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one.iloc[target_idx - 1, 0]:\n",
    "        year_match = re.search(r'\\b(\\d{4})\\b', data_df_one.iloc[target_idx, 0])\n",
    "        year = year_match.group(0) if year_match else \"Unknown\"\n",
    "        home_fee_match = re.search(r'£(\\d{4})', data_df_one.iloc[target_idx, 1].replace(',', ''))\n",
    "        overseas_fee_match = re.search(r'£(\\d{5})', data_df_one.iloc[target_idx, 2].replace(',', ''))\n",
    "        home_fee = int(home_fee_match.group(1)) if home_fee_match else None\n",
    "        overseas_fee = int(overseas_fee_match.group(1)) if overseas_fee_match else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row = pd.DataFrame({\n",
    "    'Department': [f\"All {year}\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee],\n",
    "    'Overseas fees': [overseas_fee]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df = pd.concat([additional_row, processed_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f023a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294269a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b447c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
