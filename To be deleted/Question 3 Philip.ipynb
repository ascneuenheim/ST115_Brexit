{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9bbaff",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Setup ChromeDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "search_url = \"https://eprints.lse.ac.uk/cgi/search/advanced\"\n",
    "driver.get(search_url)\n",
    "\n",
    "# Prepare a DataFrame for storing results\n",
    "columns = ['Department'] + [str(year) for year in range(2010, 2024)]\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# List of departments\n",
    "departments = [\n",
    "    'Geography & Environment', 'Philosophy, Logic and Scientific Method', \n",
    "    'Psychological and Behavioural Science', 'Government', 'Law', \n",
    "    'Social Policy', 'Mathematics', 'Economic History', 'Sociology', \n",
    "    'International History', 'Statistics', 'Management', 'International Relations', \n",
    "    'Anthropology', 'Economics', 'Language Centre', 'Accounting', 'Finance', \n",
    "    'Methodology', 'School of Public Policy', \n",
    "    'European Institute', 'Media and Communications', 'Health Policy', \n",
    "    'International Development', 'Gender Studies'\n",
    "]\n",
    "\n",
    "# Process each department\n",
    "for department in departments:\n",
    "    row_data = {'Department': department}\n",
    "    driver.get(search_url)  # Navigate back to the main search page for each department\n",
    "    try:\n",
    "        divisions_select = Select(driver.find_element(By.ID, \"divisions\"))  # Locate the dropdown again\n",
    "        divisions_select.select_by_visible_text(department)\n",
    "        available = True\n",
    "    except NoSuchElementException:\n",
    "        available = False\n",
    "        print(f\"Department {department} not found.\")\n",
    "    \n",
    "    if available:\n",
    "        for year in range(2010, 2024):\n",
    "            try:\n",
    "                wait = WebDriverWait(driver, 5)\n",
    "                date_input = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"input[name='date']\")))\n",
    "                date_input.clear()\n",
    "                date_input.send_keys(str(year))\n",
    "                date_input.send_keys(Keys.RETURN)\n",
    "\n",
    "                # Wait for the page to load and scrape the total results\n",
    "                total_results_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"span.ep_search_number\")))\n",
    "                total_results = total_results_elements[-1].text  # Get the text of the last element\n",
    "                row_data[str(year)] = total_results\n",
    "                print(f\"Results for {department} in {year}: {total_results}\")\n",
    "            except NoSuchElementException:\n",
    "                row_data[str(year)] = 'Element not found'\n",
    "                print(f\"Element not found for {department} in {year}.\")\n",
    "            except TimeoutException:\n",
    "                row_data[str(year)] = 'Timeout or no results'\n",
    "                print(f\"Timeout or no results for {department} in {year}.\")\n",
    "            driver.get('https://eprints.lse.ac.uk/cgi/search/archive/advanced')\n",
    "            divisions_select = Select(driver.find_element(By.ID, \"divisions\"))  # Locate the dropdown again\n",
    "            divisions_select.select_by_visible_text(department)\n",
    "    # Append the results of this department to the DataFrame and save incrementally\n",
    "    new_row = pd.DataFrame([row_data])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    results_df.to_csv('department_yearly_results.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Data scraping completed and saved to 'Data/department_yearly_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b4f44",
   "metadata": {},
   "source": [
    "###########FINISHED 15:08\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import csv\n",
    "\n",
    "def find_next_containing_row(data_frame, start_index, column_index, text):\n",
    "    for idx in range(start_index, len(data_frame)):\n",
    "        cell_content = str(data_frame.iloc[idx, column_index])\n",
    "        if pd.notna(cell_content) and text in cell_content:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def find_first_non_empty_cell_and_extract_fee(data_frame, start_index, column_index):\n",
    "    for idx in range(start_index, min(start_index + 10, len(data_frame))):\n",
    "        cell_content = data_frame.iloc[idx, column_index]\n",
    "        if pd.notna(cell_content) and cell_content != '':\n",
    "            first_word = cell_content.split()[0]\n",
    "            fee = ''.join(filter(str.isdigit, first_word))\n",
    "            fee = fee.replace(',', '')\n",
    "            return fee\n",
    "    print(\"No non-empty cell found within the specified range.\")\n",
    "    return None\n",
    "\n",
    "def clean_course_name(course_name):\n",
    "    return str(course_name).replace('MSc in', 'MSc').strip()  # Removes 'MSc in' and trims any leading/trailing whitespace\n",
    "\n",
    "def integrate_and_process_data(year):\n",
    "    cleaned_fees_output_path = f'Test/CleanedFees{year}.csv'\n",
    "    grouped_output_path = f'Test/Grouped_Fees{year}_by_Department_and_Level.csv'\n",
    "\n",
    "    # Load the cleaned fees data and the department information\n",
    "    cleaned_fees_df = pd.read_csv(cleaned_fees_output_path)\n",
    "    department_info_df = pd.read_csv('data/PhilipOutput.csv')\n",
    "\n",
    "    # Define a function to find the department for a given course name\n",
    "    def find_department(course_name, department_df):\n",
    "        match = department_df[department_df['Course Name'].str.strip().eq(course_name.strip())]\n",
    "        if not match.empty:\n",
    "            return match['Department'].iloc[0]\n",
    "        return \"Department not found\"\n",
    "\n",
    "    # Apply the function to add a new 'Department' column to the cleaned fees DataFrame\n",
    "    cleaned_fees_df['Department'] = cleaned_fees_df['Course'].apply(lambda x: find_department(x, department_info_df))\n",
    "\n",
    "    # Convert the Home Fee and Overseas Fee columns to numeric values for calculation\n",
    "    cleaned_fees_df['Home Fee'] = pd.to_numeric(cleaned_fees_df['Home Fee'], errors='coerce')\n",
    "    cleaned_fees_df['Overseas Fee'] = pd.to_numeric(cleaned_fees_df['Overseas Fee'], errors='coerce')\n",
    "\n",
    "    # Calculate the fee difference and add it as a new column\n",
    "    cleaned_fees_df['Fee Difference'] = cleaned_fees_df['Overseas Fee'] - cleaned_fees_df['Home Fee']\n",
    "\n",
    "    # Group the data by 'Department' and 'Level', and calculate the average fee difference for each group\n",
    "    grouped_data = cleaned_fees_df.groupby(['Department', 'Level']).agg({\n",
    "        'Fee Difference': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the grouped data to a new CSV file\n",
    "    grouped_data.to_csv(grouped_output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Output the path to the saved file to confirm where it has been saved\n",
    "    print(f\"Grouped data for {year} saved to:\", grouped_output_path)\n",
    "\n",
    "    # Display the grouped data for verification\n",
    "    display(grouped_data)\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        for page in pdf.pages:\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                for row in table:\n",
    "                    while len(row) < 10:\n",
    "                        row.append('')\n",
    "                    processed_row = row[:3] + [''] * 7\n",
    "                    all_tables.append(processed_row)\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "for year in range(2018, 2025):  # from 2018 to 2024\n",
    "    pdf_path = f'Data/TuitionFees/Fees{year}.pdf'\n",
    "    output_csv_path = f'Test/Fees{year}.csv'\n",
    "    updated_all_courses_output_path = f'Test/CleanedFees{year}.csv'\n",
    "\n",
    "    extract_tables_from_pdf(pdf_path, output_csv_path)\n",
    "    fees_df = pd.read_csv(output_csv_path, encoding='latin-1')\n",
    "\n",
    "    home_fee_index = find_next_containing_row(fees_df, 0, 1, \"Home\")\n",
    "    undergrad_home_fee = find_first_non_empty_cell_and_extract_fee(fees_df, home_fee_index + 1, 1)\n",
    "    overseas_fee_index = find_next_containing_row(fees_df, 0, 2, \"Overseas\")\n",
    "    undergrad_overseas_fee = find_first_non_empty_cell_and_extract_fee(fees_df, overseas_fee_index + 1, 2)\n",
    "\n",
    "    has_undergraduate = False\n",
    "    all_courses_fees_detailed = []\n",
    "    for index, row in fees_df.iterrows():\n",
    "        if isinstance(row.iloc[0], str) and any(x in row.iloc[0] for x in ['BSc', 'BA', 'MSc']):\n",
    "            course_name = clean_course_name(row.iloc[0].split(' - ')[0])\n",
    "            level = \"Postgraduate\" if \"MSc\" in course_name else \"Undergraduate\"\n",
    "            if level == \"Undergraduate\":\n",
    "                has_undergraduate = True\n",
    "            home_fee = row.iloc[1] if not pd.isna(row.iloc[1]) else (undergrad_home_fee if level == \"Undergraduate\" else '')\n",
    "            overseas_fee = row.iloc[2] if not pd.isna(row.iloc[2]) else ''\n",
    "            home_fee = ''.join(filter(str.isdigit, home_fee))\n",
    "            overseas_fee = ''.join(filter(str.isdigit, overseas_fee))\n",
    "            all_courses_fees_detailed.append([course_name, home_fee, overseas_fee, level])\n",
    "\n",
    "    if not has_undergraduate:\n",
    "        all_courses_fees_detailed.append([\"Undergraduate Courses\", undergrad_home_fee, undergrad_overseas_fee, \"Undergraduate\"])\n",
    "\n",
    "    all_courses_df_detailed = pd.DataFrame(all_courses_fees_detailed, columns=['Course', 'Home Fee', 'Overseas Fee', 'Level'])\n",
    "    all_courses_df_detailed.to_csv(updated_all_courses_output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Processed data for {year}.\")\n",
    "\n",
    "    # Integrate and process the data for the current year\n",
    "    integrate_and_process_data(year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5f347",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########FINISHED 15:08\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "FinalPath='Test/FinalTableFees.csv'\n",
    "\n",
    "# Load the CSV files\n",
    "fees_2018 = pd.read_csv('Test/Grouped_Fees2019_by_Department_and_Level.csv')\n",
    "fees_2019 = pd.read_csv('Test/Grouped_Fees2019_by_Department_and_Level.csv')\n",
    "fees_2020 = pd.read_csv('Test/Grouped_Fees2020_by_Department_and_Level.csv')\n",
    "fees_2021 = pd.read_csv('Test/Grouped_Fees2021_by_Department_and_Level.csv')\n",
    "fees_2022 = pd.read_csv('Test/Grouped_Fees2022_by_Department_and_Level.csv')\n",
    "fees_2023 = pd.read_csv('Test/Grouped_Fees2023_by_Department_and_Level.csv')\n",
    "fees_2024 = pd.read_csv('Test/Grouped_Fees2024_by_Department_and_Level.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Merge 2023 and 2024 data\n",
    "merged_fees = pd.merge(fees_2023, fees_2024, on=['Department', 'Level'], suffixes=('_2023', '_2024'))\n",
    "\n",
    "\n",
    "\n",
    "# Rename the Fee Difference column for 2022 data\n",
    "fees_2022.rename(columns={'Fee Difference': 'Fee Difference_2022'}, inplace=True)\n",
    "\n",
    "# Extract the universal undergraduate fee for 2022\n",
    "universal_undergrad_fee_2022 = fees_2022.loc[\n",
    "    (fees_2022['Department'] == 'Department not found') & (fees_2022['Level'] == 'Undergraduate'),\n",
    "    'Fee Difference_2022'\n",
    "].values[0]\n",
    "\n",
    "# Merge the 2022 data into the merged 2023 and 2024 data\n",
    "final_merged_fees = pd.merge(merged_fees, fees_2022[['Department', 'Level', 'Fee Difference_2022']], on=['Department', 'Level'], how='left')\n",
    "\n",
    "# Fill NaN values for undergraduate levels with the universal undergraduate fee for 2022\n",
    "final_merged_fees.loc[(final_merged_fees['Level'] == 'Undergraduate') & (final_merged_fees['Fee Difference_2022'].isna()), 'Fee Difference_2022'] = universal_undergrad_fee_2022\n",
    "\n",
    "# Reorder columns so that 'Fee Difference_2022' is to the left of 'Fee Difference_2023'\n",
    "column_order = ['Department', 'Level', 'Fee Difference_2022', 'Fee Difference_2023', 'Fee Difference_2024']\n",
    "final_merged_fees = final_merged_fees[column_order]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fees_2021.rename(columns={'Fee Difference': 'Fee Difference_2021'}, inplace=True)\n",
    "\n",
    "universal_undergrad_fee_2021 = fees_2021.loc[\n",
    "    (fees_2021['Department'] == 'Department not found') & (fees_2021['Level'] == 'Undergraduate'),\n",
    "    'Fee Difference_2021'\n",
    "].values[0]\n",
    "\n",
    "final_merged_fees = pd.merge(final_merged_fees, fees_2021[['Department', 'Level', 'Fee Difference_2021']], on=['Department', 'Level'], how='left')\n",
    "\n",
    "final_merged_fees.loc[(final_merged_fees['Level'] == 'Undergraduate') & (final_merged_fees['Fee Difference_2021'].isna()), 'Fee Difference_2021'] = universal_undergrad_fee_2021\n",
    "\n",
    "column_order = ['Department', 'Level', 'Fee Difference_2021', 'Fee Difference_2022', 'Fee Difference_2023', 'Fee Difference_2024']\n",
    "final_merged_fees = final_merged_fees[column_order]\n",
    "\n",
    "\n",
    "\n",
    "fees_2020.rename(columns={'Fee Difference': 'Fee Difference_2020'}, inplace=True)\n",
    "\n",
    "universal_undergrad_fee_2020 = fees_2020.loc[\n",
    "    (fees_2020['Department'] == 'Department not found') & (fees_2020['Level'] == 'Undergraduate'),\n",
    "    'Fee Difference_2020'\n",
    "].values[0]\n",
    "\n",
    "final_merged_fees = pd.merge(final_merged_fees, fees_2020[['Department', 'Level', 'Fee Difference_2020']], on=['Department', 'Level'], how='left')\n",
    "\n",
    "final_merged_fees.loc[(final_merged_fees['Level'] == 'Undergraduate') & (final_merged_fees['Fee Difference_2020'].isna()), 'Fee Difference_2020'] = universal_undergrad_fee_2020\n",
    "\n",
    "column_order = ['Department', 'Level', 'Fee Difference_2020', 'Fee Difference_2021','Fee Difference_2022', 'Fee Difference_2023', 'Fee Difference_2024']\n",
    "final_merged_fees = final_merged_fees[column_order]\n",
    "\n",
    "\n",
    "\n",
    "fees_2019.rename(columns={'Fee Difference': 'Fee Difference_2019'}, inplace=True)\n",
    "\n",
    "universal_undergrad_fee_2019 = fees_2019.loc[\n",
    "    (fees_2019['Department'] == 'Department not found') & (fees_2019['Level'] == 'Undergraduate'),\n",
    "    'Fee Difference_2019'\n",
    "].values[0]\n",
    "\n",
    "final_merged_fees = pd.merge(final_merged_fees, fees_2019[['Department', 'Level', 'Fee Difference_2019']], on=['Department', 'Level'], how='left')\n",
    "\n",
    "final_merged_fees.loc[(final_merged_fees['Level'] == 'Undergraduate') & (final_merged_fees['Fee Difference_2019'].isna()), 'Fee Difference_2019'] = universal_undergrad_fee_2019\n",
    "\n",
    "column_order = ['Department', 'Level','Fee Difference_2019', 'Fee Difference_2020', 'Fee Difference_2021','Fee Difference_2022', 'Fee Difference_2023', 'Fee Difference_2024']\n",
    "final_merged_fees = final_merged_fees[column_order]\n",
    "\n",
    "\n",
    "\n",
    "fees_2018.rename(columns={'Fee Difference': 'Fee Difference_2018'}, inplace=True)\n",
    "\n",
    "universal_undergrad_fee_2018 = fees_2018.loc[\n",
    "    (fees_2018['Department'] == 'Department not found') & (fees_2018['Level'] == 'Undergraduate'),\n",
    "    'Fee Difference_2018'\n",
    "].values[0]\n",
    "\n",
    "final_merged_fees = pd.merge(final_merged_fees, fees_2018[['Department', 'Level', 'Fee Difference_2018']], on=['Department', 'Level'], how='left')\n",
    "\n",
    "final_merged_fees.loc[(final_merged_fees['Level'] == 'Undergraduate') & (final_merged_fees['Fee Difference_2018'].isna()), 'Fee Difference_2018'] = universal_undergrad_fee_2018\n",
    "\n",
    "column_order = ['Department', 'Level','Fee Difference_2018','Fee Difference_2019', 'Fee Difference_2020', 'Fee Difference_2021','Fee Difference_2022', 'Fee Difference_2023', 'Fee Difference_2024']\n",
    "final_merged_fees = final_merged_fees[column_order]\n",
    "\n",
    "\n",
    "final_merged_fees.to_csv(FinalPath, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "# Display the final table\n",
    "display(final_merged_fees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c678e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e9b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "final_merged_fees = final_merged_fees[final_merged_fees['Department'] != \"Department not found\"]\n",
    "final_merged_fees['Department'] = final_merged_fees['Department'].str.replace(\"Department of \", \"\", regex=False)\n",
    "\n",
    "second_column_name = final_merged_fees.columns[1]  # Adjust the index if your column order is different\n",
    "final_merged_fees[second_column_name] = final_merged_fees[second_column_name].str.replace(\"Undergraduate\", \"UG\", regex=False)\n",
    "final_merged_fees[second_column_name] = final_merged_fees[second_column_name].str.replace(\"Postgraduate\", \"PG\", regex=False)\n",
    "\n",
    "final_merged_fees.columns = final_merged_fees.columns.str.replace(\"_\", \" \", regex=False)\n",
    "\n",
    "final_merged_fees.drop(final_merged_fees.columns[2], axis=1, inplace=True)\n",
    "final_merged_fees.drop(final_merged_fees.columns[7], axis=1, inplace=True)\n",
    "\n",
    "final_merged_fees.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final_merged_fees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8810863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb162630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entrances_df_eu = pd.read_csv(\"Data/EU_Entrances_Question_Three.csv\")\n",
    "entrances_df_eu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fa19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56890a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging the dataframes on 'Department' and 'Level'\n",
    "extra_eu_fees_merged = pd.merge(final_merged_fees, entrances_df_eu, on=['Department', 'Level'], suffixes=('_fees', '_entrances'))\n",
    "\n",
    "# Prepare a new dataframe with the same 'Department' and 'Level' columns\n",
    "extra_eu_fees_result = extra_eu_fees_merged[['Department', 'Level']].copy()\n",
    "\n",
    "# Multiply corresponding year columns for extra EU fees\n",
    "years = ['2019', '2020', '2021', '2022', '2023']\n",
    "for year in years:\n",
    "    fee_col = f'Fee Difference {year}'\n",
    "    entrance_col = f'Entrances {year}'\n",
    "    extra_eu_fees_result[f'Extra Fees through EU {year}'] = extra_eu_fees_merged[fee_col] * extra_eu_fees_merged[entrance_col]\n",
    "    \n",
    "# List of year columns in the extra_eu_fees_result dataframe that need conversion to integers\n",
    "year_columns = ['Extra Fees through EU 2019', 'Extra Fees through EU 2020', 'Extra Fees through EU 2021', 'Extra Fees through EU 2022', 'Extra Fees through EU 2023']\n",
    "\n",
    "# Convert these columns to integers to remove decimals\n",
    "for column in year_columns:\n",
    "    extra_eu_fees_result[column] = extra_eu_fees_result[column].astype(int)\n",
    "\n",
    "\n",
    "# Print or use extra_eu_fees_result as needed\n",
    "extra_eu_fees_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7c53c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extra_eu_fees_result = extra_eu_fees_result.drop('Level', axis=1)\n",
    "extra_eu_fees_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432235dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = extra_eu_fees_result.groupby('Department')[['Extra Fees through EU 2019', 'Extra Fees through EU 2020', 'Extra Fees through EU 2021', 'Extra Fees through EU 2022', 'Extra Fees through EU 2023']].sum()\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a516870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38931b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7dcb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "publications = pd.read_csv(\"Data/department_yearly_results.csv\")\n",
    "publications['Department'] = publications['Department'].str.replace('&', 'and')\n",
    "years_to_drop = [str(year) for year in range(2010, 2019)]\n",
    "publications = publications.drop(columns=years_to_drop)\n",
    "\n",
    "publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total publications for each department\n",
    "publications['Total'] = publications.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# Sort the dataframe by total publications in descending order\n",
    "publications = publications.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# Reindexing to maintain the new order\n",
    "publications = publications.reset_index(drop=True)\n",
    "\n",
    "# Now, proceed with plotting the bar chart as before\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "indices = np.arange(len(publications['Department']))\n",
    "\n",
    "# Plotting\n",
    "colors = ['#4c72b0', '#dd8452', '#55a868', '#c44e52', '#8172b2']  # Muted blue, soft terracotta, muted green, dark red, purplish blue\n",
    "widths = [\n",
    "    publications['2019'].values,\n",
    "    publications['2020'].values,\n",
    "    publications['2021'].values,\n",
    "    publications['2022'].values,\n",
    "    publications['2023'].values\n",
    "]\n",
    "\n",
    "# Ensure widths are numeric and handle potential NaNs\n",
    "widths = [np.nan_to_num(w.astype(float)) for w in widths]\n",
    "\n",
    "# Cumulative width for the 'left' argument\n",
    "cumulative_width = np.zeros(len(publications))\n",
    "\n",
    "for width, color, year in zip(widths, colors, range(2019, 2024)):\n",
    "    ax.barh(indices, width, color=color, label=str(year), left=cumulative_width)\n",
    "    cumulative_width += width\n",
    "\n",
    "ax.set(yticks=indices, yticklabels=publications['Department'])\n",
    "ax.set_xlabel('Number of Publications')\n",
    "ax.set_title('Publications by Department over 2019-2023')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104889b4",
   "metadata": {},
   "source": [
    "The horizontally stacked bar chart above visualises the number of annual publications of different departments over the years 2019 to 2023. \n",
    "\n",
    "While the relative ranking of departments by the number of publications appears relatively stable, there are exceptions with notable increases and fluctuations, particularly around 2021. Departments such as Gender Studies, Law, and Economics showed a significant increase in publications during this year. The increase is visually identifiable by a longer green section compared to the blue and orange ones. On the other hand some department's publicaiton output decreased from 2020 to 2021.\n",
    "\n",
    "This might be a direct consequence as through the change in tuition fees in 2021 due to Brexit, the fees that these departments collected might have changed significantly and as a result their funding avaiable for research increased or decreasing accordingly.\n",
    "\n",
    "However this analysis is limited in the sense that there are many other factors that could have caused these changes in 2021. Particularly the trend for each department depends on  its size, funding, and the nature of the research field itself. Thus it is hard to directly identify the changed tuition fee structure of Brexit as the cause of this change in trend. Therefore a more rigorous analysis is required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af051f28",
   "metadata": {},
   "source": [
    "Now the publication data will be merged with the data on the extra fees that were collected from EU students:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470ca8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "department_fees_publications_df = pd.merge(publications, new_dataframe, on='Department', how='inner')\n",
    "\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "\n",
    "department_fees_publications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ad94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the column names\n",
    "column_names = department_fees_publications_df.columns\n",
    "\n",
    "# Reorganize the column names\n",
    "new_column_order = ['Department']\n",
    "for year in range(2019, 2024):\n",
    "    new_column_order.append(str(year))\n",
    "    new_column_order.append(f'Extra Fees through EU {year}')\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "department_fees_publications_df = department_fees_publications_df[new_column_order]\n",
    "department_fees_publications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_columns = {}\n",
    "for column in department_fees_publications_df.columns:\n",
    "    if column.isdigit():\n",
    "        renamed_columns[column] = f'Publications {column}'\n",
    "\n",
    "department_fees_publications_df = department_fees_publications_df.rename(columns=renamed_columns)\n",
    "department_fees_publications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns containing \"2019\" or \"2020\" in their name\n",
    "columns_to_drop = department_fees_publications_df.columns[department_fees_publications_df.columns.str.contains('2019|2020')]\n",
    "department_fees_publications_df = department_fees_publications_df.drop(columns=columns_to_drop)\n",
    "department_fees_publications_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1e8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee66d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correct the script based on the printed column names\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correctly referencing DataFrame and column names\n",
    "heatmap_data = department_fees_publications_df.pivot_table(index=\"Department\", values=['Extra Fees through EU 2021', 'Extra Fees through EU 2022', 'Extra Fees through EU 2023'], aggfunc='sum') / 1_000_000  # Convert to millions\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "heat_map = sns.heatmap(heatmap_data, ax=ax, annot=True, fmt=\".2f\", cmap='viridis', annot_kws={'size':10}, vmax=1.00)\n",
    "ax.set_title('Heatmap of Extra Fees by Department and Year (in Millions)', fontsize=16)\n",
    "ax.set_xlabel('Year', fontsize=14)\n",
    "ax.set_ylabel('Department', fontsize=14)\n",
    "ax.set_xticklabels(['2021', '2022', '2023'], rotation=0, fontsize=12)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)\n",
    "\n",
    "# Annotate each cell with \"M\"\n",
    "for text in ax.texts:\n",
    "    text.set_text(text.get_text() + \"M\")\n",
    "\n",
    "# Adjusting the colorbar labels to exclude values over 1.00M\n",
    "colorbar = ax.collections[0].colorbar\n",
    "colorbar.set_label('Extra Fees (Millions M)', fontsize=12)\n",
    "colorbar.set_ticks([x for x in colorbar.get_ticks() if x <= 1.00])\n",
    "colorbar.set_ticklabels([f\"{x:.2f}M\" for x in colorbar.get_ticks()])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38847218",
   "metadata": {},
   "source": [
    "The heatmap above provides an initial insight into which departments have benefited most from the changes in tuition fee structures following Brexit. It was generated by calculating the increase in fees paid by EU students, defined as the difference between the overseas fee and the home fee, and then multiplying this by the number of EU entrants to these departments over the specified years. This effectively represents the total increase in tuition fees received from EU students by each department\n",
    "\n",
    "Immediately the yellow government field stands out which showed that the government department incurred an additional 1 million pounds in tuition fees from European students in 2021. However, this result appears to be an anomaly as it declines quickly in the following year before increasing again so its hard to interpret this more comprehensively.\n",
    "\n",
    "However as this heatmap does not provide any information on department size it does not make sense to look at absolute values further because it is uncertain whether high numbers are a result of high number of EU entrants or high fees. \n",
    "\n",
    "Certain departments such as Finance, Geography, Economic histroy and international development showed consistent growth througout these periods. This suggests that these courses have increased in popularity among EU students despite them now paying more fees for these courses. This is an important metric for LSE as it can perhaps see what makes these courses increase in attractiveness despite raised fees to ensure the university can continue attracting good talent.\n",
    "\n",
    "While it is hard to find more general trends and there seem to be much fluctuations across departments, the overall trend can be considered to be increasing. This again implies that LSE continues to attract EU students after the changed tuition fees. \n",
    "\n",
    "Moreover as the tuition fee structure only changed for students entering in 2021 there is not that much historical data from which trends can be interpreted more clearly. Moreover, it is uncertain how this increase in fees is allocated across departments, for example whether it goes into research, etc. Even more importantly this does not provide any insights into the total fees generated by each department which is arguably the more important metric. For example perhaps following Brexit these departments generated more fees from EU students but overall their collected fees went down due to other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438853d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare a new DataFrame to hold transformed data\n",
    "new_rows = []\n",
    "\n",
    "# Loop through each year and create new rows\n",
    "for year in [2021, 2022, 2023]:\n",
    "    temp_df = department_fees_publications_df[['Department', f'Publications {year}', f'Extra Fees through EU {year}']].copy()\n",
    "    temp_df['Year'] = year\n",
    "    temp_df.rename(columns={f'Publications {year}': 'Publications',\n",
    "                            f'Extra Fees through EU {year}': 'Extra Fees'}, inplace=True)\n",
    "    temp_df['Department'] = temp_df['Department'] + ' ' + str(year)\n",
    "    new_rows.append(temp_df)\n",
    "\n",
    "# Concatenate all new rows\n",
    "long_publications_extraFees_df = pd.concat(new_rows)\n",
    "\n",
    "# Sort and reset index for better readability\n",
    "long_publications_extraFees_df = long_publications_extraFees_df.sort_values(by=['Department']).reset_index(drop=True)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "long_publications_extraFees_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5461035",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long_publications_extraFees_df.drop(columns=['Year'], inplace=True)\n",
    "long_publications_extraFees_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2feb0",
   "metadata": {},
   "source": [
    "As previously mentioned, it is hard to determine how the increased tuition fees generated from EU students is allocated within departments. We will now try to examine this more precisely.\n",
    "\n",
    "Research notably is a very important component of any university department. We try to proxy for research using the number of publications of each department as a higher number of publications indicates a higher research activity.\n",
    "\n",
    "\n",
    "NUR PAAR JAHRE, VLLT IST DER EFFEKT AUF RESEARCH MIT EINEM LAG DA RESEARCH JA RELATIV LANG DAUERN KANN UND DESHALB MAN DAS EHER NACH PAAR JAHREN SEHEN KANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda95f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming long_publications_extraFees_df is already loaded\n",
    "\n",
    "# Convert data types to float (if they are not already floats)\n",
    "long_publications_extraFees_df['Extra Fees'] = pd.to_numeric(long_publications_extraFees_df['Extra Fees'], errors='coerce')\n",
    "long_publications_extraFees_df['Publications'] = pd.to_numeric(long_publications_extraFees_df['Publications'], errors='coerce')\n",
    "\n",
    "# Drop any rows with missing data after the conversion\n",
    "long_publications_extraFees_df = long_publications_extraFees_df.dropna()\n",
    "\n",
    "# Perform linear regression\n",
    "X = sm.add_constant(long_publications_extraFees_df['Extra Fees'])  # adding a constant\n",
    "model = sm.OLS(long_publications_extraFees_df['Publications'], X).fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(model.summary())\n",
    "\n",
    "# Plotting the result without text parameter\n",
    "fig = px.scatter(long_publications_extraFees_df, x='Extra Fees', y='Publications', trendline=\"ols\",\n",
    "                 labels={\"Extra_Fees\": \"Extra Fees\", \"Publications\": \"Publications\"},\n",
    "                 title=\"Regression of Publications on Extra Fees\")\n",
    "\n",
    "# Customizing hover data to only show department name when hovered over\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"Extra Fees: %{x}<br>Publications: %{y}<br>Department: %{text}\"\n",
    ")\n",
    "\n",
    "# Adding the department names as hover text\n",
    "fig.add_scatter(x=long_publications_extraFees_df['Extra Fees'], y=long_publications_extraFees_df['Publications'],\n",
    "                mode='markers', hoverinfo='text', text=long_publications_extraFees_df['Department'],\n",
    "                showlegend=False)\n",
    "\n",
    "# Update layout for centered title\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        'text': \"Regression of Publications on Extra Fees through EU students\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604c029",
   "metadata": {},
   "source": [
    "The above regresses the number of publications on the additional fees generated by EU students across departments through the years 2021 to 2023. This is meant to examine whether a higher extra fees generated EU students in a particular years corresponds to a higher number of publications of that department within a particular year. Continuing the notion of publications proxying research, the idea here is that if there would be a positive regression coefficient it would imply that these additional fees are allocated towards research.\n",
    "\n",
    "However, as already seen by just inspecting the dots across the graph, these are scattered without indication of any trend. This is confirmed by the coefficient of extra fees being almost 0 and not significant at all (p-value of 0.961). \n",
    "\n",
    "Therefore, no trend can be interpreted from this graph and a higher amount of fees generated by EU students does not seem to result in more/less research. Thus, the data is still not revealing of how these additional fees are allocated. \n",
    "\n",
    "At least from this simplified lense the effect of changed tuition structure due to Brexit did not seem to impact research of these departments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
