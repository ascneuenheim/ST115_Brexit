{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c74e6f76",
   "metadata": {},
   "source": [
    "# Data for all Questions - Applications/Offers/Entrances for departments by nationality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75757d41",
   "metadata": {},
   "source": [
    "Converting the pdf to csv:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da875d",
   "metadata": {},
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import tabula\n",
    "import jpype\n",
    "\n",
    "\n",
    "# URL of the PDF download link\n",
    "#pdf_download_url = \"https://public.tableau.com/vizql/w/ApplicationsOffersandEntrants/v/About/tempfile/sessions/6CFB072D66F548F0BD680B6D8269BD44-0:0/?key=2889495739&keepfile=yes&attachment=yes\"\n",
    "#pdf_download_url = \"https://public.tableau.com/vizql/w/LSEStatisticsonStudents/v/TableA/tempfile/sessions/E54A8D2F36614981A37995A0DF6C69BC-0:0/?key=674594458&keepfile=yes&attachment=yes\"\n",
    "# Send a GET request to download the PDF file\n",
    "#response = requests.get(pdf_download_url)\n",
    "\n",
    "# Save the content of the response to a file with .pdf extension\n",
    "file_path = \"Data/LSE_Students_acceptance_program_v1.pdf\"\n",
    "#with open(file_path, \"wb\") as f:\n",
    "#    f.write(response.content)\n",
    "\n",
    "# Extract the table from the PDF file\n",
    "tables = tabula.read_pdf(file_path, pages='all', multiple_tables=True)\n",
    "\n",
    "# Check if any tables are extracted\n",
    "if tables:\n",
    "    # Concatenate all tables into one DataFrame if there are multiple\n",
    "    combined_table = pd.concat(tables, ignore_index=True)\n",
    "    \n",
    "    # Save the combined table to a CSV file\n",
    "    csv_file = \"Data/table_v2.csv\"\n",
    "    combined_table.to_csv(csv_file, index=False)\n",
    "    print(f\"Table saved to {csv_file}\")\n",
    "else:\n",
    "    print(\"No table found in the PDF file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884fab8e",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6ec67",
   "metadata": {},
   "source": [
    "Undergraduate courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6201199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. Results saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up the WebDriver for Chrome.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')  # Bypass OS security model\n",
    "    options.add_argument('--disable-dev-shm-usage')  # Overcome limited resource problems\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def print_department_text(html_content):\n",
    "    \"\"\"Extracts and returns the text after the <h2 class=\"card__title\"> tag.\"\"\"\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    card_titles = soup.find_all('h2', class_='card__title')\n",
    "    departments = [title.text.strip() for title in card_titles]\n",
    "    return departments\n",
    "\n",
    "def print_why_study_with_us_section(driver, course_link):\n",
    "    \"\"\"Returns the HTML content of the 'why study with us' section.\"\"\"\n",
    "    driver.get(course_link)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "    try:\n",
    "        why_study_with_us_section = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'why-study-with-us'))\n",
    "        )\n",
    "        html_content = why_study_with_us_section.get_attribute('outerHTML')\n",
    "        return print_department_text(html_content)\n",
    "    except TimeoutException:\n",
    "        print(\"Failed to locate or extract the 'why study with us' section.\")\n",
    "        return []\n",
    "\n",
    "# Setup WebDriver\n",
    "driver = setup_driver()\n",
    "initial_url = \"https://www.lse.ac.uk/programmes/search-courses?studyType=0%2F1%2F26%2F85%2F86\"\n",
    "driver.get(initial_url)\n",
    "\n",
    "def process_course_page(course_link):\n",
    "    \"\"\" Visits each course link and extracts the course name, median salary, and department. \"\"\"\n",
    "    departments = print_why_study_with_us_section(driver, course_link)\n",
    "    department = ', '.join(departments) if departments else \"Department not found.\"\n",
    "    \n",
    "    try:\n",
    "        course_name = driver.find_element(By.CSS_SELECTOR, 'h1.hero__title span').text.strip()\n",
    "    except NoSuchElementException:\n",
    "        course_name = \"Course name not found.\"\n",
    "    try:\n",
    "        salary_div = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'section#graduate-destinations div.salary')))\n",
    "        median_salary = salary_div.text.strip()\n",
    "    except TimeoutException:\n",
    "        median_salary = \"Salary not found.\"\n",
    "\n",
    "    return course_name, median_salary, department\n",
    "\n",
    "def navigate_to_next_page():\n",
    "    \"\"\"Navigates to the next page if possible.\"\"\"\n",
    "    try:\n",
    "        next_page_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//li[contains(@class, 'next')]//button[contains(., 'Next')]\")))\n",
    "        next_page_button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "        return driver.current_url\n",
    "    except TimeoutException:\n",
    "        return None\n",
    "\n",
    "courses_info = []\n",
    "current_page_url = initial_url\n",
    "\n",
    "while True:\n",
    "    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'h2.card__title a')))\n",
    "    courses = [(elem.get_attribute('href'), elem.text) for elem in driver.find_elements(By.CSS_SELECTOR, 'h2.card__title a')]\n",
    "    for course_link, _ in courses:\n",
    "        course_name, median_salary, department = process_course_page(course_link)\n",
    "        courses_info.append((course_name, median_salary, department))\n",
    "        driver.get(current_page_url)\n",
    "    new_page_url = navigate_to_next_page()\n",
    "    if new_page_url:\n",
    "        current_page_url = new_page_url\n",
    "    else:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save results to a CSV file\n",
    "csv_file_path = 'Data/output2804.csv'\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Course Name', 'Median Salary', 'Department'])\n",
    "    writer.writerows(courses_info)\n",
    "\n",
    "print(\"Data extraction complete. Results saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79445b",
   "metadata": {},
   "source": [
    "Postgraduate courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2603c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£33,000\n",
      "£42,000\n",
      "Salary not found.\n",
      "£35,000\n",
      "£30,000\n",
      "£30,000\n",
      "£34,000\n",
      "£30,000\n",
      "£30,000\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "£34,000\n",
      "Salary not found.\n",
      "£30,000\n",
      "£30,000\n",
      "£38,000\n",
      "£32,000\n",
      "£35,000\n",
      "Salary not found.\n",
      "£32,000\n",
      "Salary not found.\n",
      "£33,000\n",
      "£30,000\n",
      "£34,000\n",
      "£32,000\n",
      "£30,000\n",
      "Salary not found.\n",
      "£34,000\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "£30,000\n",
      "£30,000\n",
      "Salary not found.\n",
      "£32,000\n",
      "Salary not found.\n",
      "£35,000\n",
      "£39,500\n",
      "£35,000\n",
      "Salary not found.\n",
      "£38,000\n",
      "Salary not found.\n",
      "£33,000\n",
      "Salary not found.\n",
      "£33,000\n",
      "£30,000\n",
      "£28,000\n",
      "£30,000\n",
      "£32,000\n",
      "£30,000\n",
      "£32,000\n",
      "£32,000\n",
      "£30,000\n",
      "£34,000\n",
      "Salary not found.\n",
      "£34,000\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "£33,000\n",
      "Salary not found.\n",
      "£30,000\n",
      "£38,000\n",
      "£33,000\n",
      "£34,500\n",
      "Salary not found.\n",
      "£33,000\n",
      "£28,000\n",
      "Salary not found.\n",
      "£32,000\n",
      "£30,000\n",
      "£42,000\n",
      "£30,000\n",
      "£28,000\n",
      "£38,000\n",
      "Salary not found.\n",
      "£38,000\n",
      "Salary not found.\n",
      "£33,000\n",
      "£30,000\n",
      "£35,000\n",
      "£28,000\n",
      "£38,000\n",
      "Salary not found.\n",
      "£38,000\n",
      "Salary not found.\n",
      "£38,000\n",
      "£33,000\n",
      "£30,000\n",
      "£38,000\n",
      "£35,000\n",
      "£28,000\n",
      "£28,000\n",
      "£30,000\n",
      "£38,000\n",
      "£30,000\n",
      "£30,000\n",
      "£35,000\n",
      "£42,000\n",
      "£38,000\n",
      "£33,000\n",
      "£30,000\n",
      "£34,000\n",
      "Salary not found.\n",
      "£38,000\n",
      "£28,000\n",
      "£42,000\n",
      "£32,000\n",
      "£32,000\n",
      "Salary not found.\n",
      "Salary not found.\n",
      "£32,000\n",
      "Salary not found.\n",
      "£35,000\n",
      "£35,000\n",
      "£28,000\n",
      "£30,000\n",
      "£35,000\n",
      "£32,000\n",
      "£35,000\n",
      "£35,000\n",
      "£33,000\n",
      "£30,000\n",
      "£33,000\n",
      "£33,000\n",
      "£48,000\n",
      "£28,000\n",
      "£28,000\n",
      "£35,000\n",
      "£35,000\n",
      "Salary not found.\n",
      "Data extraction complete. Results added to 'output2804.csv'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up the WebDriver for Chrome.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def process_course_page(driver, course_link):\n",
    "    \"\"\"Visits each course link and extracts the course name, median salary, and department for postgraduate courses.\"\"\"\n",
    "    driver.get(course_link)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extracting course name\n",
    "    course_name_elem = soup.find('h1', class_='pageTitle')\n",
    "    course_name = course_name_elem.text.strip() if course_name_elem else \"Course name not found.\"\n",
    "\n",
    "    # Finding department\n",
    "    department_elem = soup.find('li', class_='keyDetails__item--dept')\n",
    "    department = department_elem.text.strip() if department_elem else \"Department not found.\"\n",
    "\n",
    "    # Extracting median salary directly from the Careers accordion content\n",
    "    # Extracting median salary directly from the Careers accordion content\n",
    "    median_salary = \"Salary not found.\"\n",
    "    careers_accordion = soup.find('h1', class_='accordion__title', string=lambda text: 'Careers' in text if text else False)\n",
    "    if careers_accordion:\n",
    "        careers_content = careers_accordion.find_next('div', class_='accordion__content')\n",
    "        if careers_content:\n",
    "            salary_tag = careers_content.find('strong', string=lambda text: \"Median salary\" in text if text else False)\n",
    "            if salary_tag:\n",
    "                median_salary = salary_tag.next_sibling.strip() if salary_tag.next_sibling else \"Salary not found.\"\n",
    "\n",
    "    print(median_salary)\n",
    "    return course_name, median_salary, department\n",
    "\n",
    "\n",
    "# Main scraping function\n",
    "def scrape_courses(base_url):\n",
    "    driver = setup_driver()\n",
    "    driver.get(base_url)\n",
    "    courses_info = []\n",
    "    current_page_url = base_url  # Initialize current page URL\n",
    "\n",
    "    while True:\n",
    "        # Wait for the course links to be visible and then collect them\n",
    "        WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'h2.card__title a')))\n",
    "        course_elements = driver.find_elements(By.CSS_SELECTOR, 'h2.card__title a')\n",
    "        courses = [(elem.get_attribute('href'), elem.text) for elem in course_elements]\n",
    "\n",
    "        for course_link, _ in courses:\n",
    "            driver.get(course_link)\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "            course_info = process_course_page(driver, course_link)\n",
    "            courses_info.append(course_info)\n",
    "            driver.get(current_page_url)  # Go back to the current list page, not the base URL\n",
    "            WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'h2.card__title a')))  # Wait until all course links are visible again\n",
    "\n",
    "        new_page_url = navigate_to_next_page(driver)\n",
    "        if new_page_url:\n",
    "            current_page_url = new_page_url  # Update the current page URL\n",
    "            driver.get(new_page_url)  # Navigate to the next page\n",
    "            WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))  # Ensure the page is loaded\n",
    "        else:\n",
    "            break  # Exit the loop if there are no more pages\n",
    "\n",
    "    driver.quit()\n",
    "    return courses_info\n",
    "\n",
    "def navigate_to_next_page(driver):\n",
    "    \"\"\"Navigates to the next page if possible.\"\"\"\n",
    "    try:\n",
    "        next_page_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//li[contains(@class, 'next')]//button[contains(., 'Next')]\")))\n",
    "        next_page_button.click()\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "        return driver.current_url\n",
    "    except TimeoutException:\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Appends the data to a CSV file or creates it if it doesn't exist.\"\"\"\n",
    "    file_exists = os.path.isfile(filename)  # Check if the file already exists\n",
    "\n",
    "    with open(filename, 'a', newline='') as file:  # Open the file in append mode\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writerow(['Course Name', 'Median Salary', 'Department'])  # Write header only if the file does not exist\n",
    "        \n",
    "        writer.writerows(data)\n",
    "\n",
    "\n",
    "# URL for postgraduate courses\n",
    "postgraduate_url = \"https://www.lse.ac.uk/programmes/search-courses?studyType=0%2F1%2F26%2F85%2F87\"\n",
    "postgraduate_courses = scrape_courses(postgraduate_url)\n",
    "save_to_csv(postgraduate_courses, 'Data/output2804.csv')\n",
    "print(\"Data extraction complete. Results added to 'output2804.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde4041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6419f680",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cde0576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_gdp_by_country():\n",
    "    url = \"https://www.worldometers.info/gdp/gdp-by-country/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    rows = soup.find_all('tr')\n",
    "    gdp_by_country_data = []\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        if len(cells) >= 7:\n",
    "            country = cells[1].text.strip()\n",
    "            gdp = cells[2].text.strip().replace('$', '').replace(',', '')\n",
    "            population = cells[5].text.strip().replace(',', '')\n",
    "            gdp_per_capita = cells[6].text.strip().replace('$', '').replace(',', '')\n",
    "            gdp_by_country_data.append((country, gdp, population, gdp_per_capita))\n",
    "    \n",
    "    return gdp_by_country_data\n",
    "\n",
    "def merge_with_country_nationality_mapping(gdp_data, country_nationality_file):\n",
    "    country_nationality_map = {}\n",
    "    with open(country_nationality_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            country_name = row['en_short_name']\n",
    "            nationality = row['nationality']\n",
    "            country_nationality_map[country_name] = nationality\n",
    "\n",
    "    merged_data = []\n",
    "    for country, gdp, population, gdp_per_capita in gdp_data:\n",
    "        if country in country_nationality_map:\n",
    "            nationality = country_nationality_map[country]\n",
    "            merged_data.append((country, nationality, gdp, population, gdp_per_capita))\n",
    "        else:\n",
    "            merged_data.append((country, '', gdp, population, gdp_per_capita))\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "def write_to_csv(data, csv_file):\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Country', 'Nationality', 'GDP', 'Population', 'GDP per Capita'])\n",
    "        writer.writerows(data)\n",
    "\n",
    "def main():\n",
    "    gdp_by_country_data = scrape_gdp_by_country()\n",
    "    if gdp_by_country_data:\n",
    "        merged_data = merge_with_country_nationality_mapping(gdp_by_country_data, 'Data/countries.csv')\n",
    "        write_to_csv(merged_data, 'Data/merged_gdp_data.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37129b01",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87781168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Geography & Environment in 2010: 220\n",
      "Results for Geography & Environment in 2011: 296\n",
      "Results for Geography & Environment in 2012: 243\n",
      "Results for Geography & Environment in 2013: 160\n",
      "Results for Geography & Environment in 2014: 160\n",
      "Results for Geography & Environment in 2015: 108\n",
      "Results for Geography & Environment in 2016: 129\n",
      "Results for Geography & Environment in 2017: 119\n",
      "Results for Geography & Environment in 2018: 119\n",
      "Results for Geography & Environment in 2019: 117\n",
      "Results for Geography & Environment in 2020: 175\n",
      "Results for Geography & Environment in 2021: 177\n",
      "Results for Geography & Environment in 2022: 170\n",
      "Results for Geography & Environment in 2023: 145\n",
      "Results for Philosophy, Logic and Scientific Method in 2010: 98\n",
      "Results for Philosophy, Logic and Scientific Method in 2011: 60\n",
      "Results for Philosophy, Logic and Scientific Method in 2012: 66\n",
      "Results for Philosophy, Logic and Scientific Method in 2013: 68\n",
      "Results for Philosophy, Logic and Scientific Method in 2014: 46\n",
      "Results for Philosophy, Logic and Scientific Method in 2015: 60\n",
      "Results for Philosophy, Logic and Scientific Method in 2016: 50\n",
      "Results for Philosophy, Logic and Scientific Method in 2017: 69\n",
      "Results for Philosophy, Logic and Scientific Method in 2018: 55\n",
      "Results for Philosophy, Logic and Scientific Method in 2019: 64\n",
      "Results for Philosophy, Logic and Scientific Method in 2020: 60\n",
      "Results for Philosophy, Logic and Scientific Method in 2021: 63\n",
      "Results for Philosophy, Logic and Scientific Method in 2022: 66\n",
      "Results for Philosophy, Logic and Scientific Method in 2023: 61\n",
      "Results for Psychological and Behavioural Science in 2010: 79\n",
      "Results for Psychological and Behavioural Science in 2011: 116\n",
      "Results for Psychological and Behavioural Science in 2012: 69\n",
      "Results for Psychological and Behavioural Science in 2013: 99\n",
      "Results for Psychological and Behavioural Science in 2014: 88\n",
      "Results for Psychological and Behavioural Science in 2015: 92\n",
      "Results for Psychological and Behavioural Science in 2016: 84\n",
      "Results for Psychological and Behavioural Science in 2017: 77\n",
      "Results for Psychological and Behavioural Science in 2018: 91\n",
      "Results for Psychological and Behavioural Science in 2019: 77\n",
      "Results for Psychological and Behavioural Science in 2020: 125\n",
      "Results for Psychological and Behavioural Science in 2021: 152\n",
      "Results for Psychological and Behavioural Science in 2022: 156\n",
      "Results for Psychological and Behavioural Science in 2023: 146\n",
      "Results for Government in 2010: 274\n",
      "Results for Government in 2011: 211\n",
      "Results for Government in 2012: 227\n",
      "Results for Government in 2013: 190\n",
      "Results for Government in 2014: 160\n",
      "Results for Government in 2015: 156\n",
      "Results for Government in 2016: 190\n",
      "Results for Government in 2017: 142\n",
      "Results for Government in 2018: 302\n",
      "Results for Government in 2019: 106\n",
      "Results for Government in 2020: 126\n",
      "Results for Government in 2021: 85\n",
      "Results for Government in 2022: 100\n",
      "Results for Government in 2023: 113\n",
      "Results for Law in 2010: 248\n",
      "Results for Law in 2011: 205\n",
      "Results for Law in 2012: 245\n",
      "Results for Law in 2013: 192\n",
      "Results for Law in 2014: 174\n",
      "Results for Law in 2015: 164\n",
      "Results for Law in 2016: 204\n",
      "Results for Law in 2017: 180\n",
      "Results for Law in 2018: 160\n",
      "Results for Law in 2019: 85\n",
      "Results for Law in 2020: 118\n",
      "Results for Law in 2021: 146\n",
      "Results for Law in 2022: 92\n",
      "Results for Law in 2023: 117\n",
      "Results for Social Policy in 2010: 267\n",
      "Results for Social Policy in 2011: 342\n",
      "Results for Social Policy in 2012: 325\n",
      "Results for Social Policy in 2013: 305\n",
      "Results for Social Policy in 2014: 327\n",
      "Results for Social Policy in 2015: 283\n",
      "Results for Social Policy in 2016: 216\n",
      "Results for Social Policy in 2017: 196\n",
      "Results for Social Policy in 2018: 154\n",
      "Results for Social Policy in 2019: 112\n",
      "Results for Social Policy in 2020: 124\n",
      "Results for Social Policy in 2021: 116\n",
      "Results for Social Policy in 2022: 138\n",
      "Results for Social Policy in 2023: 142\n",
      "Results for Mathematics in 2010: 67\n",
      "Results for Mathematics in 2011: 49\n",
      "Results for Mathematics in 2012: 43\n",
      "Results for Mathematics in 2013: 64\n",
      "Results for Mathematics in 2014: 42\n",
      "Results for Mathematics in 2015: 45\n",
      "Results for Mathematics in 2016: 58\n",
      "Results for Mathematics in 2017: 64\n",
      "Results for Mathematics in 2018: 50\n",
      "Results for Mathematics in 2019: 53\n",
      "Results for Mathematics in 2020: 91\n",
      "Results for Mathematics in 2021: 56\n",
      "Results for Mathematics in 2022: 64\n",
      "Results for Mathematics in 2023: 50\n",
      "Results for Economic History in 2010: 87\n",
      "Results for Economic History in 2011: 102\n",
      "Results for Economic History in 2012: 104\n",
      "Results for Economic History in 2013: 59\n",
      "Results for Economic History in 2014: 51\n",
      "Results for Economic History in 2015: 33\n",
      "Results for Economic History in 2016: 50\n",
      "Results for Economic History in 2017: 46\n",
      "Results for Economic History in 2018: 51\n",
      "Results for Economic History in 2019: 49\n",
      "Results for Economic History in 2020: 45\n",
      "Results for Economic History in 2021: 39\n",
      "Results for Economic History in 2022: 38\n",
      "Results for Economic History in 2023: 53\n",
      "Results for Sociology in 2010: 99\n",
      "Results for Sociology in 2011: 77\n",
      "Results for Sociology in 2012: 92\n",
      "Results for Sociology in 2013: 92\n",
      "Results for Sociology in 2014: 70\n",
      "Results for Sociology in 2015: 91\n",
      "Results for Sociology in 2016: 103\n",
      "Results for Sociology in 2017: 70\n",
      "Results for Sociology in 2018: 68\n",
      "Results for Sociology in 2019: 45\n",
      "Results for Sociology in 2020: 54\n",
      "Results for Sociology in 2021: 59\n",
      "Results for Sociology in 2022: 57\n",
      "Results for Sociology in 2023: 50\n",
      "Results for International History in 2010: 79\n",
      "Results for International History in 2011: 89\n",
      "Results for International History in 2012: 71\n",
      "Results for International History in 2013: 68\n",
      "Results for International History in 2014: 65\n",
      "Results for International History in 2015: 43\n",
      "Results for International History in 2016: 67\n",
      "Results for International History in 2017: 49\n",
      "Results for International History in 2018: 56\n",
      "Results for International History in 2019: 41\n",
      "Results for International History in 2020: 43\n",
      "Results for International History in 2021: 37\n",
      "Results for International History in 2022: 35\n",
      "Results for International History in 2023: 32\n",
      "Results for Statistics in 2010: 56\n",
      "Results for Statistics in 2011: 63\n",
      "Results for Statistics in 2012: 51\n",
      "Results for Statistics in 2013: 57\n",
      "Results for Statistics in 2014: 37\n",
      "Results for Statistics in 2015: 52\n",
      "Results for Statistics in 2016: 44\n",
      "Results for Statistics in 2017: 67\n",
      "Results for Statistics in 2018: 53\n",
      "Results for Statistics in 2019: 42\n",
      "Results for Statistics in 2020: 63\n",
      "Results for Statistics in 2021: 54\n",
      "Results for Statistics in 2022: 84\n",
      "Results for Statistics in 2023: 94\n",
      "Results for Management in 2010: 234\n",
      "Results for Management in 2011: 225\n",
      "Results for Management in 2012: 187\n",
      "Results for Management in 2013: 228\n",
      "Results for Management in 2014: 161\n",
      "Results for Management in 2015: 152\n",
      "Results for Management in 2016: 167\n",
      "Results for Management in 2017: 151\n",
      "Results for Management in 2018: 114\n",
      "Results for Management in 2019: 87\n",
      "Results for Management in 2020: 114\n",
      "Results for Management in 2021: 108\n",
      "Results for Management in 2022: 112\n",
      "Results for Management in 2023: 95\n",
      "Results for International Relations in 2010: 183\n",
      "Results for International Relations in 2011: 183\n",
      "Results for International Relations in 2012: 148\n",
      "Results for International Relations in 2013: 120\n",
      "Results for International Relations in 2014: 138\n",
      "Results for International Relations in 2015: 145\n",
      "Results for International Relations in 2016: 120\n",
      "Results for International Relations in 2017: 149\n",
      "Results for International Relations in 2018: 89\n",
      "Results for International Relations in 2019: 85\n",
      "Results for International Relations in 2020: 90\n",
      "Results for International Relations in 2021: 91\n",
      "Results for International Relations in 2022: 93\n",
      "Results for International Relations in 2023: 101\n",
      "Results for Anthropology in 2010: 81\n",
      "Results for Anthropology in 2011: 97\n",
      "Results for Anthropology in 2012: 96\n",
      "Results for Anthropology in 2013: 91\n",
      "Results for Anthropology in 2014: 44\n",
      "Results for Anthropology in 2015: 61\n",
      "Results for Anthropology in 2016: 39\n",
      "Results for Anthropology in 2017: 55\n",
      "Results for Anthropology in 2018: 45\n",
      "Results for Anthropology in 2019: 36\n",
      "Results for Anthropology in 2020: 51\n",
      "Results for Anthropology in 2021: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Anthropology in 2022: 57\n",
      "Results for Anthropology in 2023: 50\n",
      "Results for Economics in 2010: 164\n",
      "Results for Economics in 2011: 171\n",
      "Results for Economics in 2012: 149\n",
      "Results for Economics in 2013: 164\n",
      "Results for Economics in 2014: 115\n",
      "Results for Economics in 2015: 100\n",
      "Results for Economics in 2016: 120\n",
      "Results for Economics in 2017: 107\n",
      "Results for Economics in 2018: 97\n",
      "Results for Economics in 2019: 114\n",
      "Results for Economics in 2020: 194\n",
      "Results for Economics in 2021: 139\n",
      "Results for Economics in 2022: 142\n",
      "Results for Economics in 2023: 134\n",
      "Timeout or no results for Language Centre in 2010.\n",
      "Timeout or no results for Language Centre in 2011.\n",
      "Timeout or no results for Language Centre in 2012.\n",
      "Timeout or no results for Language Centre in 2013.\n",
      "Timeout or no results for Language Centre in 2014.\n",
      "Timeout or no results for Language Centre in 2015.\n",
      "Timeout or no results for Language Centre in 2016.\n",
      "Timeout or no results for Language Centre in 2017.\n",
      "Timeout or no results for Language Centre in 2018.\n",
      "Timeout or no results for Language Centre in 2019.\n",
      "Timeout or no results for Language Centre in 2020.\n",
      "Timeout or no results for Language Centre in 2021.\n",
      "Timeout or no results for Language Centre in 2022.\n",
      "Timeout or no results for Language Centre in 2023.\n",
      "Results for Accounting in 2010: 51\n",
      "Results for Accounting in 2011: 32\n",
      "Results for Accounting in 2012: 41\n",
      "Results for Accounting in 2013: 35\n",
      "Results for Accounting in 2014: 30\n",
      "Results for Accounting in 2015: 34\n",
      "Results for Accounting in 2016: 41\n",
      "Results for Accounting in 2017: 32\n",
      "Results for Accounting in 2018: 25\n",
      "Results for Accounting in 2019: 22\n",
      "Results for Accounting in 2020: 16\n",
      "Results for Accounting in 2021: 25\n",
      "Results for Accounting in 2022: 30\n",
      "Results for Accounting in 2023: 14\n",
      "Results for Finance in 2010: 37\n",
      "Results for Finance in 2011: 61\n",
      "Results for Finance in 2012: 57\n",
      "Results for Finance in 2013: 48\n",
      "Results for Finance in 2014: 43\n",
      "Results for Finance in 2015: 43\n",
      "Results for Finance in 2016: 58\n",
      "Results for Finance in 2017: 23\n",
      "Results for Finance in 2018: 32\n",
      "Results for Finance in 2019: 22\n",
      "Results for Finance in 2020: 37\n",
      "Results for Finance in 2021: 33\n",
      "Results for Finance in 2022: 30\n",
      "Results for Finance in 2023: 30\n",
      "Results for Methodology in 2010: 37\n",
      "Results for Methodology in 2011: 43\n",
      "Results for Methodology in 2012: 40\n",
      "Results for Methodology in 2013: 55\n",
      "Results for Methodology in 2014: 42\n",
      "Results for Methodology in 2015: 55\n",
      "Results for Methodology in 2016: 53\n",
      "Results for Methodology in 2017: 60\n",
      "Results for Methodology in 2018: 60\n",
      "Results for Methodology in 2019: 39\n",
      "Results for Methodology in 2020: 76\n",
      "Results for Methodology in 2021: 58\n",
      "Results for Methodology in 2022: 64\n",
      "Results for Methodology in 2023: 72\n",
      "Results for School of Public Policy in 2010: 23\n",
      "Results for School of Public Policy in 2011: 18\n",
      "Results for School of Public Policy in 2012: 3\n",
      "Results for School of Public Policy in 2013: 4\n",
      "Results for School of Public Policy in 2014: 2\n",
      "Results for School of Public Policy in 2015: 5\n",
      "Results for School of Public Policy in 2016: 7\n",
      "Results for School of Public Policy in 2017: 5\n",
      "Results for School of Public Policy in 2018: 160\n",
      "Results for School of Public Policy in 2019: 18\n",
      "Results for School of Public Policy in 2020: 34\n",
      "Results for School of Public Policy in 2021: 50\n",
      "Results for School of Public Policy in 2022: 26\n",
      "Results for School of Public Policy in 2023: 41\n",
      "Results for European Institute in 2010: 174\n",
      "Results for European Institute in 2011: 174\n",
      "Results for European Institute in 2012: 243\n",
      "Results for European Institute in 2013: 187\n",
      "Results for European Institute in 2014: 154\n",
      "Results for European Institute in 2015: 145\n",
      "Results for European Institute in 2016: 183\n",
      "Results for European Institute in 2017: 117\n",
      "Results for European Institute in 2018: 321\n",
      "Results for European Institute in 2019: 63\n",
      "Results for European Institute in 2020: 147\n",
      "Results for European Institute in 2021: 86\n",
      "Results for European Institute in 2022: 100\n",
      "Results for European Institute in 2023: 93\n",
      "Results for Media and Communications in 2010: 250\n",
      "Results for Media and Communications in 2011: 243\n",
      "Results for Media and Communications in 2012: 229\n",
      "Results for Media and Communications in 2013: 243\n",
      "Results for Media and Communications in 2014: 187\n",
      "Results for Media and Communications in 2015: 178\n",
      "Results for Media and Communications in 2016: 195\n",
      "Results for Media and Communications in 2017: 176\n",
      "Results for Media and Communications in 2018: 103\n",
      "Results for Media and Communications in 2019: 89\n",
      "Results for Media and Communications in 2020: 125\n",
      "Results for Media and Communications in 2021: 141\n",
      "Results for Media and Communications in 2022: 133\n",
      "Results for Media and Communications in 2023: 137\n",
      "Results for Health Policy in 2010: 11\n",
      "Results for Health Policy in 2011: 10\n",
      "Results for Health Policy in 2012: 11\n",
      "Results for Health Policy in 2013: 8\n",
      "Results for Health Policy in 2014: 15\n",
      "Results for Health Policy in 2015: 27\n",
      "Results for Health Policy in 2016: 19\n",
      "Results for Health Policy in 2017: 39\n",
      "Results for Health Policy in 2018: 80\n",
      "Results for Health Policy in 2019: 101\n",
      "Results for Health Policy in 2020: 149\n",
      "Results for Health Policy in 2021: 178\n",
      "Results for Health Policy in 2022: 189\n",
      "Results for Health Policy in 2023: 208\n",
      "Results for International Development in 2010: 117\n",
      "Results for International Development in 2011: 92\n",
      "Results for International Development in 2012: 104\n",
      "Results for International Development in 2013: 128\n",
      "Results for International Development in 2014: 115\n",
      "Results for International Development in 2015: 143\n",
      "Results for International Development in 2016: 110\n",
      "Results for International Development in 2017: 102\n",
      "Results for International Development in 2018: 90\n",
      "Results for International Development in 2019: 111\n",
      "Results for International Development in 2020: 127\n",
      "Results for International Development in 2021: 104\n",
      "Results for International Development in 2022: 89\n",
      "Results for International Development in 2023: 80\n",
      "Results for Gender Studies in 2010: 58\n",
      "Results for Gender Studies in 2011: 44\n",
      "Results for Gender Studies in 2012: 52\n",
      "Results for Gender Studies in 2013: 40\n",
      "Results for Gender Studies in 2014: 40\n",
      "Results for Gender Studies in 2015: 41\n",
      "Results for Gender Studies in 2016: 34\n",
      "Results for Gender Studies in 2017: 23\n",
      "Results for Gender Studies in 2018: 28\n",
      "Results for Gender Studies in 2019: 19\n",
      "Results for Gender Studies in 2020: 21\n",
      "Results for Gender Studies in 2021: 20\n",
      "Results for Gender Studies in 2022: 18\n",
      "Results for Gender Studies in 2023: 24\n",
      "Data scraping completed and saved to 'Data/department_yearly_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "# Setup ChromeDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "search_url = \"https://eprints.lse.ac.uk/cgi/search/advanced\"\n",
    "driver.get(search_url)\n",
    "\n",
    "# Prepare a DataFrame for storing results\n",
    "columns = ['Department'] + [str(year) for year in range(2010, 2024)]\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# List of departments\n",
    "departments = [\n",
    "    'Geography & Environment', 'Philosophy, Logic and Scientific Method', \n",
    "    'Psychological and Behavioural Science', 'Government', 'Law', \n",
    "    'Social Policy', 'Mathematics', 'Economic History', 'Sociology', \n",
    "    'International History', 'Statistics', 'Management', 'International Relations', \n",
    "    'Anthropology', 'Economics', 'Language Centre', 'Accounting', 'Finance', \n",
    "    'Methodology', 'School of Public Policy', \n",
    "    'European Institute', 'Media and Communications', 'Health Policy', \n",
    "    'International Development', 'Gender Studies'\n",
    "]\n",
    "\n",
    "# Process each department\n",
    "for department in departments:\n",
    "    row_data = {'Department': department}\n",
    "    driver.get(search_url)  # Navigate back to the main search page for each department\n",
    "    try:\n",
    "        divisions_select = Select(driver.find_element(By.ID, \"divisions\"))  # Locate the dropdown again\n",
    "        divisions_select.select_by_visible_text(department)\n",
    "        available = True\n",
    "    except NoSuchElementException:\n",
    "        available = False\n",
    "        print(f\"Department {department} not found.\")\n",
    "    \n",
    "    if available:\n",
    "        for year in range(2010, 2024):\n",
    "            try:\n",
    "                wait = WebDriverWait(driver, 2)\n",
    "                date_input = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"input[name='date']\")))\n",
    "                date_input.clear()\n",
    "                date_input.send_keys(str(year))\n",
    "                date_input.send_keys(Keys.RETURN)\n",
    "\n",
    "                # Wait for the page to load and scrape the total results\n",
    "                total_results_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"span.ep_search_number\")))\n",
    "                total_results = total_results_elements[-1].text  # Get the text of the last element\n",
    "                row_data[str(year)] = total_results\n",
    "                print(f\"Results for {department} in {year}: {total_results}\")\n",
    "            except NoSuchElementException:\n",
    "                row_data[str(year)] = 'Element not found'\n",
    "                print(f\"Element not found for {department} in {year}.\")\n",
    "            except TimeoutException:\n",
    "                row_data[str(year)] = 'Timeout or no results'\n",
    "                print(f\"Timeout or no results for {department} in {year}.\")\n",
    "            driver.get('https://eprints.lse.ac.uk/cgi/search/archive/advanced')\n",
    "            divisions_select = Select(driver.find_element(By.ID, \"divisions\"))  # Locate the dropdown again\n",
    "            divisions_select.select_by_visible_text(department)\n",
    "    # Append the results of this department to the DataFrame and save incrementally\n",
    "    new_row = pd.DataFrame([row_data])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    results_df.to_csv('Data/department_yearly_results.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Data scraping completed and saved to 'Data/department_yearly_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46391522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed Table-of-fees-2024-25-20Feb24-Updated-Home-PGR-fee.pdf to Fees2024.pdf\n",
      "Renamed Table-of-fees-2023-24-7Nov23.pdf to Fees2023.pdf\n",
      "Renamed Comb2022ToF-Final-19July23.pdf to Fees2022.pdf\n",
      "Renamed ToF-3Aug21FinalComb.pdf to Fees2021.pdf\n",
      "Renamed 2020-Table-of-Fees-25Jun20.pdf to Fees2020.pdf\n",
      "Renamed 2019-Table-of-Fees.pdf to Fees2019.pdf\n",
      "Renamed 2018-19-Fees-Table.pdf to Fees2018.pdf\n",
      "Renamed 2017-18-Fees-Table.pdf to Fees2017.pdf\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "def setup_driver(download_dir_absolute):\n",
    "    \"\"\"Sets up the WebDriver for Chrome.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": download_dir_absolute,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"plugins.always_open_pdf_externally\": True\n",
    "    })\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def extract_year_from_filename(filename):\n",
    "    # Try to find a four-digit year first\n",
    "    four_digit_year_match = re.search(r'(\\d{4})', filename)\n",
    "    if four_digit_year_match:\n",
    "        return four_digit_year_match.group(1)\n",
    "    # If not found, look for a two-digit year\n",
    "    two_digit_year_match = re.search(r'(\\d{2})', filename)\n",
    "    if two_digit_year_match:\n",
    "        return '20' + two_digit_year_match.group(1)\n",
    "    # Return None if no year pattern is found\n",
    "    return None\n",
    "\n",
    "def rename_downloaded_file(download_dir, original_filename, year):\n",
    "    original_path = os.path.join(download_dir, original_filename)\n",
    "    new_filename = f\"Fees{year}.pdf\"\n",
    "    new_path = os.path.join(download_dir, new_filename)\n",
    "    os.rename(original_path, new_path)\n",
    "    print(f\"Renamed {original_filename} to {new_filename}\")\n",
    "\n",
    "def download_pdfs_by_class(base_url, class_name, download_dir):\n",
    "    driver = setup_driver(download_dir)\n",
    "    driver.get(base_url)\n",
    "    time.sleep(1)  # Adjust based on your internet speed\n",
    "    links = driver.find_elements(By.CLASS_NAME, class_name)\n",
    "\n",
    "    for link in links:\n",
    "        href = link.get_attribute('href')\n",
    "        # Skip the unwanted PDF\n",
    "        if \"Fee-approval-cycle-2024.pdf\" in href:\n",
    "            continue\n",
    "        if href and href.endswith('.pdf'):\n",
    "            # Extract the original file name\n",
    "            original_filename = href.split('/')[-1]\n",
    "            # Extract year from the file name\n",
    "            year = extract_year_from_filename(original_filename)\n",
    "            if year:\n",
    "                # Open the link in a new tab and download the file\n",
    "                driver.execute_script(f\"window.open('{href}');\")\n",
    "                time.sleep(1)  # Adjust for page load\n",
    "                # The file is automatically downloaded to `download_dir`\n",
    "                # Need to wait for the download to complete here (omitted for simplicity)\n",
    "                # Rename the file after ensuring the download has completed\n",
    "                rename_downloaded_file(download_dir, original_filename, year)\n",
    "            # Switch back to the main window\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Base URL and class name remain the same\n",
    "base_url = 'https://info.lse.ac.uk/staff/divisions/Planning-Division/Table-of-Fees'\n",
    "class_name = 'sys_21'\n",
    "download_dir_relative = 'Data/TuitionFees'\n",
    "\n",
    "# Create the download directory if it doesn't exist\n",
    "download_dir_absolute = os.path.abspath(download_dir_relative)\n",
    "if not os.path.exists(download_dir_absolute):\n",
    "    os.makedirs(download_dir_absolute)\n",
    "\n",
    "# Call the download function\n",
    "download_pdfs_by_class(base_url, class_name, download_dir_absolute)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
