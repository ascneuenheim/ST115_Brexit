{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327d7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import csv\n",
    "\n",
    "def extract_tables_from_pdf(pdf_path, output_csv_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        all_tables = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page in pdf.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                all_tables.extend(table)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            for row in all_tables:\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path = 'Data/2020-Table-of-Fees-25Jun20.pdf'\n",
    "output_csv_path = 'Data/2020_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf(pdf_path, output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f95c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ee47e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_66316/797634393.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_66316/797634393.py:9: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 244: expected 5 fields, saw 8\n",
      "Skipping line 245: expected 5 fields, saw 8\n",
      "Skipping line 246: expected 5 fields, saw 8\n",
      "Skipping line 247: expected 5 fields, saw 8\n",
      "Skipping line 248: expected 5 fields, saw 8\n",
      "Skipping line 249: expected 5 fields, saw 8\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "Skipping line 262: expected 5 fields, saw 9\n",
      "Skipping line 263: expected 5 fields, saw 9\n",
      "Skipping line 264: expected 5 fields, saw 9\n",
      "Skipping line 265: expected 5 fields, saw 9\n",
      "Skipping line 266: expected 5 fields, saw 9\n",
      "Skipping line 267: expected 5 fields, saw 9\n",
      "Skipping line 268: expected 5 fields, saw 9\n",
      "Skipping line 269: expected 5 fields, saw 9\n",
      "Skipping line 270: expected 5 fields, saw 9\n",
      "Skipping line 271: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_66316/797634393.py:78: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3 = pd.Series(col3_values).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department</th>\n",
       "      <th>Program</th>\n",
       "      <th>Home fees</th>\n",
       "      <th>Overseas fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All 2020</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>21570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28080</td>\n",
       "      <td>28464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23179</td>\n",
       "      <td>24134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19952</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28969</td>\n",
       "      <td>29185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18160</td>\n",
       "      <td>25768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19452</td>\n",
       "      <td>23436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16656</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28441</td>\n",
       "      <td>28703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21912</td>\n",
       "      <td>26184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18624</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17968</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21987</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24336</td>\n",
       "      <td>27376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17296</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Media And Communication</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>International..</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19470</td>\n",
       "      <td>23732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Department    Program  Home fees  \\\n",
       "0                                 All 2020  UG Degree       9250   \n",
       "1                               Accounting  PG Taught      28080   \n",
       "2                         Economic History  PG Taught      14640   \n",
       "3                                Economics  PG Taught      23179   \n",
       "4                       European Institute  PG Taught      19952   \n",
       "5                                  Finance  PG Taught      28969   \n",
       "6                           Gender Studies  PG Taught      14640   \n",
       "7                Geography And Environment  PG Taught      14640   \n",
       "8                            Health Policy  PG Taught      18160   \n",
       "9                International Development  PG Taught      14640   \n",
       "10                 International Relations  PG Taught      19452   \n",
       "11                              Law School  PG Taught      16656   \n",
       "12                              Management  PG Taught      28441   \n",
       "13                             Mathematics  PG Taught      21912   \n",
       "14                 Media And Communication  PG Taught      20616   \n",
       "15  Philosophy Logic And Scientific Method  PG Taught      18624   \n",
       "16   Psychological And Behavioural Science  PG Taught      17968   \n",
       "17                 School of Public Policy  PG Taught      21987   \n",
       "18                               Sociology  PG Taught      14640   \n",
       "19                              Statistics  PG Taught      24336   \n",
       "20                            Anthropology  PG Taught      17296   \n",
       "21                   International History  PG Taught      14640   \n",
       "22                 Media And Communication  PG Taught      20616   \n",
       "23                         International..  PG Taught      19470   \n",
       "\n",
       "    Overseas fees  \n",
       "0           21570  \n",
       "1           28464  \n",
       "2           22608  \n",
       "3           24134  \n",
       "4           22608  \n",
       "5           29185  \n",
       "6           22608  \n",
       "7           22608  \n",
       "8           25768  \n",
       "9           22608  \n",
       "10          23436  \n",
       "11          24264  \n",
       "12          28703  \n",
       "13          26184  \n",
       "14          22608  \n",
       "15          22608  \n",
       "16          22608  \n",
       "17          24264  \n",
       "18          22608  \n",
       "19          27376  \n",
       "20          22608  \n",
       "21          22608  \n",
       "22          22608  \n",
       "23          23732  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path = 'Data/2020_Fees.csv'  # Adjust path as necessary\n",
    "csv_path = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  # Adjust path as necessary\n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one = pd.read_csv(output_csv_path, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df = pd.read_csv(csv_path)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df['Dept_Program'] = data_df['Department'] + \" \" + data_df['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs = data_df['Dept_Program'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs = []\n",
    "for combo in unique_dept_programs:\n",
    "    if isinstance(combo, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo:\n",
    "            original_department = combo.replace(\" PG Taught\", \"\")\n",
    "            transformed_department = original_department\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department:\n",
    "                transformed_department = transformed_department.split(\"And\")[0].strip()\n",
    "            if transformed_department == \"International History\":\n",
    "                transformed_department = \"History\"\n",
    "            if transformed_department == \"European Institute\":\n",
    "                transformed_department = \"European\"\n",
    "            if transformed_department == \"Law School\" or transformed_department == \"Law\":\n",
    "                transformed_department = \"LLM\"\n",
    "            if transformed_department == \"Philosophy Logic\":\n",
    "                transformed_department = \"Philosophy\"\n",
    "            if transformed_department == \"School of Public Policy\":\n",
    "                transformed_department = \"Public Policy\"\n",
    "            if transformed_department == \"Gender Studies\":\n",
    "                transformed_department = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department:\n",
    "                transformed_department = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed[transformed_department] = original_department\n",
    "            processed_dept_programs.append(transformed_department)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df = pd.DataFrame(processed_dept_programs, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data(dept_program):\n",
    "    matches = data_df_one[data_df_one.iloc[:, 0].str.contains(dept_program, na=False)]\n",
    "    if not matches.empty:\n",
    "        col2_values = []\n",
    "        col3_values = []\n",
    "        for _, row in matches.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2 = float(str(row[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2.is_integer():\n",
    "                    col2_values.append(int(cleaned_value_col2))\n",
    "            except ValueError:\n",
    "                col2_values.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3 = float(str(row[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3.is_integer():\n",
    "                    col3_values.append(int(cleaned_value_col3))\n",
    "            except ValueError:\n",
    "                col3_values.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2 = pd.Series(col2_values).dropna().mean()\n",
    "        avg_col3 = pd.Series(col3_values).dropna().mean()\n",
    "        return pd.Series([avg_col2, avg_col3])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df[['Home fees', 'Overseas fees']] = processed_df['Department'].apply(find_matching_data)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df['Home fees'] = processed_df['Home fees'].astype(int)\n",
    "processed_df['Overseas fees'] = processed_df['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df['Department'] = processed_df['Department'].map(original_to_transformed)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx = data_df_one.index[data_df_one.iloc[:, 0].str.contains(\"Students commencing their degree in\", na=False)].tolist()\n",
    "if idx:\n",
    "    target_idx = idx[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one.iloc[target_idx - 1, 0]:\n",
    "        year_match = re.search(r'\\b(\\d{4})\\b', data_df_one.iloc[target_idx, 0])\n",
    "        year = year_match.group(0) if year_match else \"Unknown\"\n",
    "        home_fee_match = re.search(r'£(\\d{4})', data_df_one.iloc[target_idx, 1].replace(',', ''))\n",
    "        overseas_fee_match = re.search(r'£(\\d{5})', data_df_one.iloc[target_idx, 2].replace(',', ''))\n",
    "        home_fee = int(home_fee_match.group(1)) if home_fee_match else None\n",
    "        overseas_fee = int(overseas_fee_match.group(1)) if overseas_fee_match else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row = pd.DataFrame({\n",
    "    'Department': [f\"All {year}\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee],\n",
    "    'Overseas fees': [overseas_fee]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df = pd.concat([additional_row, processed_df]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
