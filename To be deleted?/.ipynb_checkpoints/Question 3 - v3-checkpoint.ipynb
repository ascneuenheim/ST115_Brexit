{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27a0e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed Table-of-fees-2024-25-20Feb24-Updated-Home-PGR-fee.pdf to Fees2024.pdf\n",
      "Renamed Table-of-fees-2023-24-7Nov23.pdf to Fees2023.pdf\n",
      "Renamed Comb2022ToF-Final-19July23.pdf to Fees2022.pdf\n",
      "Renamed ToF-3Aug21FinalComb.pdf to Fees2021.pdf\n",
      "Renamed 2020-Table-of-Fees-25Jun20.pdf to Fees2020.pdf\n",
      "Renamed 2019-Table-of-Fees.pdf to Fees2019.pdf\n",
      "Renamed 2018-19-Fees-Table.pdf to Fees2018.pdf\n",
      "Renamed 2017-18-Fees-Table.pdf to Fees2017.pdf\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "def setup_driver(download_dir_absolute):\n",
    "    \"\"\"Sets up the WebDriver for Chrome.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": download_dir_absolute,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"plugins.always_open_pdf_externally\": True\n",
    "    })\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver\n",
    "\n",
    "def extract_year_from_filename(filename):\n",
    "    # Try to find a four-digit year first\n",
    "    four_digit_year_match = re.search(r'(\\d{4})', filename)\n",
    "    if four_digit_year_match:\n",
    "        return four_digit_year_match.group(1)\n",
    "    # If not found, look for a two-digit year\n",
    "    two_digit_year_match = re.search(r'(\\d{2})', filename)\n",
    "    if two_digit_year_match:\n",
    "        return '20' + two_digit_year_match.group(1)\n",
    "    # Return None if no year pattern is found\n",
    "    return None\n",
    "\n",
    "def rename_downloaded_file(download_dir, original_filename, year):\n",
    "    original_path = os.path.join(download_dir, original_filename)\n",
    "    new_filename = f\"Fees{year}.pdf\"\n",
    "    new_path = os.path.join(download_dir, new_filename)\n",
    "    os.rename(original_path, new_path)\n",
    "    print(f\"Renamed {original_filename} to {new_filename}\")\n",
    "\n",
    "def download_pdfs_by_class(base_url, class_name, download_dir):\n",
    "    driver = setup_driver(download_dir)\n",
    "    driver.get(base_url)\n",
    "    time.sleep(1)  # Adjust based on your internet speed\n",
    "    links = driver.find_elements(By.CLASS_NAME, class_name)\n",
    "\n",
    "    for link in links:\n",
    "        href = link.get_attribute('href')\n",
    "        # Skip the unwanted PDF\n",
    "        if \"Fee-approval-cycle-2024.pdf\" in href:\n",
    "            continue\n",
    "        if href and href.endswith('.pdf'):\n",
    "            # Extract the original file name\n",
    "            original_filename = href.split('/')[-1]\n",
    "            # Extract year from the file name\n",
    "            year = extract_year_from_filename(original_filename)\n",
    "            if year:\n",
    "                # Open the link in a new tab and download the file\n",
    "                driver.execute_script(f\"window.open('{href}');\")\n",
    "                time.sleep(1)  # Adjust for page load\n",
    "                # The file is automatically downloaded to `download_dir`\n",
    "                # Need to wait for the download to complete here (omitted for simplicity)\n",
    "                # Rename the file after ensuring the download has completed\n",
    "                rename_downloaded_file(download_dir, original_filename, year)\n",
    "            # Switch back to the main window\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "    \n",
    "    # Close the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Base URL and class name remain the same\n",
    "base_url = 'https://info.lse.ac.uk/staff/divisions/Planning-Division/Table-of-Fees'\n",
    "class_name = 'sys_21'\n",
    "download_dir_relative = 'Data/TuitionFees'\n",
    "\n",
    "# Create the download directory if it doesn't exist\n",
    "download_dir_absolute = os.path.abspath(download_dir_relative)\n",
    "if not os.path.exists(download_dir_absolute):\n",
    "    os.makedirs(download_dir_absolute)\n",
    "\n",
    "# Call the download function\n",
    "download_pdfs_by_class(base_url, class_name, download_dir_absolute)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a266cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/4120531526.py:27: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2020 = pd.read_csv(output_csv_file_2020, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/4120531526.py:27: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2020 = pd.read_csv(output_csv_file_2020, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 244: expected 5 fields, saw 8\n",
      "Skipping line 245: expected 5 fields, saw 8\n",
      "Skipping line 246: expected 5 fields, saw 8\n",
      "Skipping line 247: expected 5 fields, saw 8\n",
      "Skipping line 248: expected 5 fields, saw 8\n",
      "Skipping line 249: expected 5 fields, saw 8\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "Skipping line 262: expected 5 fields, saw 9\n",
      "Skipping line 263: expected 5 fields, saw 9\n",
      "Skipping line 264: expected 5 fields, saw 9\n",
      "Skipping line 265: expected 5 fields, saw 9\n",
      "Skipping line 266: expected 5 fields, saw 9\n",
      "Skipping line 267: expected 5 fields, saw 9\n",
      "Skipping line 268: expected 5 fields, saw 9\n",
      "Skipping line 269: expected 5 fields, saw 9\n",
      "Skipping line 270: expected 5 fields, saw 9\n",
      "Skipping line 271: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/4120531526.py:85: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3_2020 = pd.Series(col3_values_2020).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department_2020</th>\n",
       "      <th>Program_2020</th>\n",
       "      <th>Home_fees_2020</th>\n",
       "      <th>Overseas_fees_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>21570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28080</td>\n",
       "      <td>28464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23179</td>\n",
       "      <td>24134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19952</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28969</td>\n",
       "      <td>29185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18160</td>\n",
       "      <td>25768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19452</td>\n",
       "      <td>23436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16656</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>28441</td>\n",
       "      <td>28703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21912</td>\n",
       "      <td>26184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communications</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20616</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18624</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17968</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21987</td>\n",
       "      <td>24264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24336</td>\n",
       "      <td>27376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17296</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14640</td>\n",
       "      <td>22608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Department_2020 Program_2020  Home_fees_2020  \\\n",
       "0                                      All    UG Degree            9250   \n",
       "1                               Accounting    PG Taught           28080   \n",
       "2                         Economic History    PG Taught           14640   \n",
       "3                                Economics    PG Taught           23179   \n",
       "4                       European Institute    PG Taught           19952   \n",
       "5                                  Finance    PG Taught           28969   \n",
       "6                           Gender Studies    PG Taught           14640   \n",
       "7                Geography And Environment    PG Taught           14640   \n",
       "8                            Health Policy    PG Taught           18160   \n",
       "9                International Development    PG Taught           14640   \n",
       "10                 International Relations    PG Taught           19452   \n",
       "11                              Law School    PG Taught           16656   \n",
       "12                              Management    PG Taught           28441   \n",
       "13                             Mathematics    PG Taught           21912   \n",
       "14                Media And Communications    PG Taught           20616   \n",
       "15  Philosophy Logic And Scientific Method    PG Taught           18624   \n",
       "16   Psychological And Behavioural Science    PG Taught           17968   \n",
       "17                 School of Public Policy    PG Taught           21987   \n",
       "18                               Sociology    PG Taught           14640   \n",
       "19                              Statistics    PG Taught           24336   \n",
       "20                            Anthropology    PG Taught           17296   \n",
       "21                   International History    PG Taught           14640   \n",
       "\n",
       "    Overseas_fees_2020  \n",
       "0                21570  \n",
       "1                28464  \n",
       "2                22608  \n",
       "3                24134  \n",
       "4                22608  \n",
       "5                29185  \n",
       "6                22608  \n",
       "7                22608  \n",
       "8                25768  \n",
       "9                22608  \n",
       "10               23436  \n",
       "11               24264  \n",
       "12               28703  \n",
       "13               26184  \n",
       "14               22608  \n",
       "15               22608  \n",
       "16               22608  \n",
       "17               24264  \n",
       "18               22608  \n",
       "19               27376  \n",
       "20               22608  \n",
       "21               22608  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_tables_from_pdf_2020(pdf_path_2020, output_csv_path_2020):\n",
    "    with pdfplumber.open(pdf_path_2020) as pdf_2020:\n",
    "        all_tables_2020 = []\n",
    "        for page_2020 in pdf_2020.pages:\n",
    "            tables_2020 = page_2020.extract_tables()\n",
    "            for table_2020 in tables_2020:\n",
    "                all_tables_2020.extend(table_2020)\n",
    "       \n",
    "        with open(output_csv_path_2020, 'w', newline='') as csvfile_2020:\n",
    "            writer_2020 = csv.writer(csvfile_2020)\n",
    "            for row_2020 in all_tables_2020:\n",
    "                writer_2020.writerow(row_2020)\n",
    "\n",
    "pdf_path_2020 = 'Data/2020-Table-of-Fees-25Jun20.pdf'\n",
    "output_csv_path_2020 = 'Data/2020_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf_2020(pdf_path_2020, output_csv_path_2020)\n",
    "\n",
    "output_csv_file_2020 = 'Data/2020_Fees.csv'  \n",
    "csv_file_2020 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "data_df_one_2020 = pd.read_csv(output_csv_file_2020, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2020 = pd.read_csv(csv_file_2020)\n",
    "\n",
    "data_df_one_2020['Dept_Program_2020'] = data_df_2020['Department'] + \" \" + data_df_2020['Program']\n",
    "\n",
    "unique_dept_programs_2020 = data_df_one_2020['Dept_Program_2020'].unique()\n",
    "\n",
    "original_to_transformed_2020 = {}\n",
    "processed_dept_programs_2020 = []\n",
    "for combo_2020 in unique_dept_programs_2020:\n",
    "    if isinstance(combo_2020, str):\n",
    "        if \"PG Taught\" in combo_2020:\n",
    "            original_department_2020 = combo_2020.replace(\" PG Taught\", \"\")\n",
    "            transformed_department_2020 = original_department_2020\n",
    "            if \"And\" in transformed_department_2020:\n",
    "                transformed_department_2020 = transformed_department_2020.split(\"And\")[0].strip()\n",
    "            if transformed_department_2020 == \"International History\":\n",
    "                transformed_department_2020 = \"History\"\n",
    "            if transformed_department_2020 == \"European Institute\":\n",
    "                transformed_department_2020 = \"European\"\n",
    "            if transformed_department_2020 == \"Law School\" or transformed_department_2020 == \"Law\":\n",
    "                transformed_department_2020 = \"LLM\"\n",
    "            if transformed_department_2020 == \"Philosophy Logic\":\n",
    "                transformed_department_2020 = \"Philosophy\"\n",
    "            if transformed_department_2020 == \"School of Public Policy\":\n",
    "                transformed_department_2020 = \"Public Policy\"\n",
    "            if transformed_department_2020 == \"Gender Studies\":\n",
    "                transformed_department_2020 = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department_2020:\n",
    "                transformed_department_2020 = \"Psychology\"\n",
    "            \n",
    "            original_to_transformed_2020[transformed_department_2020] = original_department_2020\n",
    "            processed_dept_programs_2020.append(transformed_department_2020)\n",
    "\n",
    "processed_df_2020 = pd.DataFrame(processed_dept_programs_2020, columns=['Department_2020'])\n",
    "\n",
    "processed_df_2020.insert(1, 'Program_2020', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2020(dept_program_2020):\n",
    "    matches_2020 = data_df_one_2020[data_df_one_2020.iloc[:, 0].str.contains(dept_program_2020, na=False)]\n",
    "    if not matches_2020.empty:\n",
    "        col2_values_2020 = []\n",
    "        col3_values_2020 = []\n",
    "        for _, row_2020 in matches_2020.iterrows():\n",
    "            try:\n",
    "                cleaned_value_col2_2020 = float(str(row_2020[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2_2020.is_integer():\n",
    "                    col2_values_2020.append(int(cleaned_value_col2_2020))\n",
    "            except ValueError:\n",
    "                col2_values_2020.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3_2020 = float(str(row_2020[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3_2020.is_integer():\n",
    "                    col3_values_2020.append(int(cleaned_value_col3_2020))\n",
    "            except ValueError:\n",
    "                col3_values_2020.append(pd.NA)\n",
    "        \n",
    "        avg_col2_2020 = pd.Series(col2_values_2020).dropna().mean()\n",
    "        avg_col3_2020 = pd.Series(col3_values_2020).dropna().mean()\n",
    "        return pd.Series([avg_col2_2020, avg_col3_2020])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "processed_df_2020[['Home_fees_2020', 'Overseas_fees_2020']] = processed_df_2020['Department_2020'].apply(find_matching_data_2020)\n",
    "\n",
    "processed_df_2020.dropna(subset=['Home_fees_2020', 'Overseas_fees_2020'], inplace=True)\n",
    "\n",
    "processed_df_2020['Home_fees_2020'] = processed_df_2020['Home_fees_2020'].astype(int)\n",
    "processed_df_2020['Overseas_fees_2020'] = processed_df_2020['Overseas_fees_2020'].astype(int)\n",
    "\n",
    "processed_df_2020['Department_2020'] = processed_df_2020['Department_2020'].map(original_to_transformed_2020)\n",
    "\n",
    "processed_df_2020\n",
    "\n",
    "idx_2020 = data_df_one_2020.index[data_df_one_2020.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2020:\n",
    "    target_idx_2020 = idx_2020[0]\n",
    "    if \"Undergraduate\" in data_df_one_2020.iloc[target_idx_2020 - 1, 0]:\n",
    "        year_match_2020 = re.search(r'\\b(\\d{4})\\b', data_df_one_2020.iloc[target_idx_2020, 0])\n",
    "        year_2020 = year_match_2020.group(0) if year_match_2020 else \"Unknown\"\n",
    "        home_fee_match_2020 = re.search(r'£(\\d{4})', data_df_one_2020.iloc[target_idx_2020, 1].replace(',', ''))\n",
    "        overseas_fee_match_2020 = re.search(r'£(\\d{5})', data_df_one_2020.iloc[target_idx_2020, 2].replace(',', ''))\n",
    "        home_fee_2020 = int(home_fee_match_2020.group(1)) if home_fee_match_2020 else None\n",
    "        overseas_fee_2020 = int(overseas_fee_match_2020.group(1)) if overseas_fee_match_2020 else None\n",
    "\n",
    "additional_row_2020 = pd.DataFrame({\n",
    "    'Department_2020': [\"All\"],\n",
    "    'Program_2020': [\"UG Degree\"],\n",
    "    'Home_fees_2020': [home_fee_2020],\n",
    "    'Overseas_fees_2020': [overseas_fee_2020]\n",
    "})\n",
    "\n",
    "processed_df_2020 = pd.concat([additional_row_2020, processed_df_2020]).reset_index(drop=True)\n",
    "\n",
    "processed_df_2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e2270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325b5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259de426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2363455879.py:27: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2018 = pd.read_csv(output_csv_file_2018, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2363455879.py:27: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2018 = pd.read_csv(output_csv_file_2018, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2363455879.py:85: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3_2018 = pd.Series(col3_values_2018).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department_2018</th>\n",
       "      <th>Program_2018</th>\n",
       "      <th>Home_fees_2018</th>\n",
       "      <th>Overseas_fees_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>19152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>25080</td>\n",
       "      <td>25344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20848</td>\n",
       "      <td>21796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19936</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26599</td>\n",
       "      <td>26797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16392</td>\n",
       "      <td>23448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17480</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17988</td>\n",
       "      <td>21672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15384</td>\n",
       "      <td>22440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23670</td>\n",
       "      <td>23756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communications</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19062</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17220</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20363</td>\n",
       "      <td>20954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Social Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18048</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>20256</td>\n",
       "      <td>24204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>15992</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>13536</td>\n",
       "      <td>20904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Department_2018 Program_2018  Home_fees_2018  \\\n",
       "0                                      All    UG Degree            9250   \n",
       "1                               Accounting    PG Taught           25080   \n",
       "2                         Economic History    PG Taught           13536   \n",
       "3                                Economics    PG Taught           20848   \n",
       "4                       European Institute    PG Taught           19936   \n",
       "5                                  Finance    PG Taught           26599   \n",
       "6                           Gender Studies    PG Taught           13536   \n",
       "7                Geography And Environment    PG Taught           13536   \n",
       "8                            Health Policy    PG Taught           16392   \n",
       "9                International Development    PG Taught           17480   \n",
       "10                 International Relations    PG Taught           17988   \n",
       "11                              Law School    PG Taught           15384   \n",
       "12                              Management    PG Taught           23670   \n",
       "13                             Mathematics    PG Taught           20256   \n",
       "14                Media And Communications    PG Taught           19062   \n",
       "15  Philosophy Logic And Scientific Method    PG Taught           17220   \n",
       "16   Psychological And Behavioural Science    PG Taught           15992   \n",
       "17                 School of Public Policy    PG Taught           20363   \n",
       "18                           Social Policy    PG Taught           18048   \n",
       "19                               Sociology    PG Taught           13536   \n",
       "20                              Statistics    PG Taught           20256   \n",
       "21                            Anthropology    PG Taught           15992   \n",
       "22                   International History    PG Taught           13536   \n",
       "\n",
       "    Overseas_fees_2018  \n",
       "0                19152  \n",
       "1                25344  \n",
       "2                20904  \n",
       "3                21796  \n",
       "4                20904  \n",
       "5                26797  \n",
       "6                20904  \n",
       "7                20904  \n",
       "8                23448  \n",
       "9                20904  \n",
       "10               21672  \n",
       "11               22440  \n",
       "12               23756  \n",
       "13               24204  \n",
       "14               20904  \n",
       "15               20904  \n",
       "16               20904  \n",
       "17               20954  \n",
       "18               20904  \n",
       "19               20904  \n",
       "20               24204  \n",
       "21               20904  \n",
       "22               20904  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_tables_from_pdf_2018(pdf_path_2018, output_csv_path_2018):\n",
    "    with pdfplumber.open(pdf_path_2018) as pdf_2018:\n",
    "        all_tables_2018 = []\n",
    "        for page_2018 in pdf_2018.pages:\n",
    "            tables_2018 = page_2018.extract_tables()\n",
    "            for table_2018 in tables_2018:\n",
    "                all_tables_2018.extend(table_2018)\n",
    "       \n",
    "        with open(output_csv_path_2018, 'w', newline='') as csvfile_2018:\n",
    "            writer_2018 = csv.writer(csvfile_2018)\n",
    "            for row_2018 in all_tables_2018:\n",
    "                writer_2018.writerow(row_2018)\n",
    "\n",
    "pdf_path_2018 = 'Data/2018-19-Fees-Table.pdf'\n",
    "output_csv_path_2018 = 'Data/2018_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf_2018(pdf_path_2018, output_csv_path_2018)\n",
    "\n",
    "output_csv_file_2018 = 'Data/2018_Fees.csv'  \n",
    "csv_file_2018 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "data_df_one_2018 = pd.read_csv(output_csv_file_2018, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2018 = pd.read_csv(csv_file_2018)\n",
    "\n",
    "data_df_one_2018['Dept_Program_2018'] = data_df_2018['Department'] + \" \" + data_df_2018['Program']\n",
    "\n",
    "unique_dept_programs_2018 = data_df_one_2018['Dept_Program_2018'].unique()\n",
    "\n",
    "original_to_transformed_2018 = {}\n",
    "processed_dept_programs_2018 = []\n",
    "for combo_2018 in unique_dept_programs_2018:\n",
    "    if isinstance(combo_2018, str):\n",
    "        if \"PG Taught\" in combo_2018:\n",
    "            original_department_2018 = combo_2018.replace(\" PG Taught\", \"\")\n",
    "            transformed_department_2018 = original_department_2018\n",
    "            if \"And\" in transformed_department_2018:\n",
    "                transformed_department_2018 = transformed_department_2018.split(\"And\")[0].strip()\n",
    "            if transformed_department_2018 == \"International History\":\n",
    "                transformed_department_2018 = \"History\"\n",
    "            if transformed_department_2018 == \"European Institute\":\n",
    "                transformed_department_2018 = \"European\"\n",
    "            if transformed_department_2018 == \"Law School\" or transformed_department_2018 == \"Law\":\n",
    "                transformed_department_2018 = \"LLM\"\n",
    "            if transformed_department_2018 == \"Philosophy Logic\":\n",
    "                transformed_department_2018 = \"Philosophy\"\n",
    "            if transformed_department_2018 == \"School of Public Policy\":\n",
    "                transformed_department_2018 = \"Public Policy\"\n",
    "            if transformed_department_2018 == \"Gender Studies\":\n",
    "                transformed_department_2018 = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department_2018:\n",
    "                transformed_department_2018 = \"Psychology\"\n",
    "            \n",
    "            original_to_transformed_2018[transformed_department_2018] = original_department_2018\n",
    "            processed_dept_programs_2018.append(transformed_department_2018)\n",
    "\n",
    "processed_df_2018 = pd.DataFrame(processed_dept_programs_2018, columns=['Department_2018'])\n",
    "\n",
    "processed_df_2018.insert(1, 'Program_2018', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2018(dept_program_2018):\n",
    "    matches_2018 = data_df_one_2018[data_df_one_2018.iloc[:, 0].str.contains(dept_program_2018, na=False)]\n",
    "    if not matches_2018.empty:\n",
    "        col2_values_2018 = []\n",
    "        col3_values_2018 = []\n",
    "        for _, row_2018 in matches_2018.iterrows():\n",
    "            try:\n",
    "                cleaned_value_col2_2018 = float(str(row_2018[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2_2018.is_integer():\n",
    "                    col2_values_2018.append(int(cleaned_value_col2_2018))\n",
    "            except ValueError:\n",
    "                col2_values_2018.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3_2018 = float(str(row_2018[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3_2018.is_integer():\n",
    "                    col3_values_2018.append(int(cleaned_value_col3_2018))\n",
    "            except ValueError:\n",
    "                col3_values_2018.append(pd.NA)\n",
    "        \n",
    "        avg_col2_2018 = pd.Series(col2_values_2018).dropna().mean()\n",
    "        avg_col3_2018 = pd.Series(col3_values_2018).dropna().mean()\n",
    "        return pd.Series([avg_col2_2018, avg_col3_2018])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "processed_df_2018[['Home_fees_2018', 'Overseas_fees_2018']] = processed_df_2018['Department_2018'].apply(find_matching_data_2018)\n",
    "\n",
    "processed_df_2018.dropna(subset=['Home_fees_2018', 'Overseas_fees_2018'], inplace=True)\n",
    "\n",
    "processed_df_2018['Home_fees_2018'] = processed_df_2018['Home_fees_2018'].astype(int)\n",
    "processed_df_2018['Overseas_fees_2018'] = processed_df_2018['Overseas_fees_2018'].astype(int)\n",
    "\n",
    "processed_df_2018['Department_2018'] = processed_df_2018['Department_2018'].map(original_to_transformed_2018)\n",
    "\n",
    "processed_df_2018\n",
    "\n",
    "idx_2018 = data_df_one_2018.index[data_df_one_2018.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2018:\n",
    "    target_idx_2018 = idx_2018[0]\n",
    "    if \"Undergraduate\" in data_df_one_2018.iloc[target_idx_2018 - 1, 0]:\n",
    "        year_match_2018 = re.search(r'\\b(\\d{4})\\b', data_df_one_2018.iloc[target_idx_2018, 0])\n",
    "        year_2018 = year_match_2018.group(0) if year_match_2018 else \"Unknown\"\n",
    "        home_fee_match_2018 = re.search(r'£(\\d{4})', data_df_one_2018.iloc[target_idx_2018, 1].replace(',', ''))\n",
    "        overseas_fee_match_2018 = re.search(r'£(\\d{5})', data_df_one_2018.iloc[target_idx_2018, 2].replace(',', ''))\n",
    "        home_fee_2018 = int(home_fee_match_2018.group(1)) if home_fee_match_2018 else None\n",
    "        overseas_fee_2018 = int(overseas_fee_match_2018.group(1)) if overseas_fee_match_2018 else None\n",
    "\n",
    "additional_row_2018 = pd.DataFrame({\n",
    "    'Department_2018': [\"All\"],\n",
    "    'Program_2018': [\"UG Degree\"],\n",
    "    'Home_fees_2018': [home_fee_2018],\n",
    "    'Overseas_fees_2018': [overseas_fee_2018]\n",
    "})\n",
    "\n",
    "processed_df_2018 = pd.concat([additional_row_2018, processed_df_2018]).reset_index(drop=True)\n",
    "\n",
    "processed_df_2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c65d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c166f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2859237326.py:27: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2019 = pd.read_csv(output_csv_file_2019, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2859237326.py:27: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2019 = pd.read_csv(output_csv_file_2019, error_bad_lines=False, warn_bad_lines=True)\n",
      "Skipping line 234: expected 5 fields, saw 8\n",
      "Skipping line 235: expected 5 fields, saw 8\n",
      "Skipping line 236: expected 5 fields, saw 8\n",
      "Skipping line 237: expected 5 fields, saw 8\n",
      "Skipping line 238: expected 5 fields, saw 8\n",
      "Skipping line 239: expected 5 fields, saw 8\n",
      "Skipping line 240: expected 5 fields, saw 9\n",
      "Skipping line 241: expected 5 fields, saw 9\n",
      "Skipping line 242: expected 5 fields, saw 9\n",
      "Skipping line 243: expected 5 fields, saw 9\n",
      "Skipping line 244: expected 5 fields, saw 9\n",
      "Skipping line 245: expected 5 fields, saw 9\n",
      "Skipping line 246: expected 5 fields, saw 9\n",
      "Skipping line 247: expected 5 fields, saw 9\n",
      "Skipping line 248: expected 5 fields, saw 9\n",
      "Skipping line 249: expected 5 fields, saw 9\n",
      "Skipping line 250: expected 5 fields, saw 9\n",
      "Skipping line 251: expected 5 fields, saw 9\n",
      "Skipping line 252: expected 5 fields, saw 9\n",
      "Skipping line 253: expected 5 fields, saw 9\n",
      "Skipping line 254: expected 5 fields, saw 9\n",
      "Skipping line 255: expected 5 fields, saw 9\n",
      "Skipping line 256: expected 5 fields, saw 9\n",
      "Skipping line 257: expected 5 fields, saw 9\n",
      "Skipping line 258: expected 5 fields, saw 9\n",
      "Skipping line 259: expected 5 fields, saw 9\n",
      "Skipping line 260: expected 5 fields, saw 9\n",
      "Skipping line 261: expected 5 fields, saw 9\n",
      "\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/2859237326.py:85: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  avg_col3_2019 = pd.Series(col3_values_2019).dropna().mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department_2019</th>\n",
       "      <th>Program_2019</th>\n",
       "      <th>Home_fees_2019</th>\n",
       "      <th>Overseas_fees_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>UG Degree</td>\n",
       "      <td>9250</td>\n",
       "      <td>19920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accounting</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>26082</td>\n",
       "      <td>26358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economic History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21917</td>\n",
       "      <td>22870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>European Institute</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19192</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Finance</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>27663</td>\n",
       "      <td>27870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender Studies</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geography And Environment</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Health Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17512</td>\n",
       "      <td>24832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>International Development</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>International Relations</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>18708</td>\n",
       "      <td>22536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Law School</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16008</td>\n",
       "      <td>23328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Management</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>24575</td>\n",
       "      <td>24826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>21072</td>\n",
       "      <td>25176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Media And Communications</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>19830</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Philosophy Logic And Scientific Method</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17916</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Psychological And Behavioural Science</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>17280</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>School of Public Policy</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>22294</td>\n",
       "      <td>23570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Statistics</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>23400</td>\n",
       "      <td>26320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Anthropology</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>16640</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International History</td>\n",
       "      <td>PG Taught</td>\n",
       "      <td>14088</td>\n",
       "      <td>21744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Department_2019 Program_2019  Home_fees_2019  \\\n",
       "0                                      All    UG Degree            9250   \n",
       "1                               Accounting    PG Taught           26082   \n",
       "2                         Economic History    PG Taught           14088   \n",
       "3                                Economics    PG Taught           21917   \n",
       "4                       European Institute    PG Taught           19192   \n",
       "5                                  Finance    PG Taught           27663   \n",
       "6                           Gender Studies    PG Taught           14088   \n",
       "7                Geography And Environment    PG Taught           14088   \n",
       "8                            Health Policy    PG Taught           17512   \n",
       "9                International Development    PG Taught           14088   \n",
       "10                 International Relations    PG Taught           18708   \n",
       "11                              Law School    PG Taught           16008   \n",
       "12                              Management    PG Taught           24575   \n",
       "13                             Mathematics    PG Taught           21072   \n",
       "14                Media And Communications    PG Taught           19830   \n",
       "15  Philosophy Logic And Scientific Method    PG Taught           17916   \n",
       "16   Psychological And Behavioural Science    PG Taught           17280   \n",
       "17                 School of Public Policy    PG Taught           22294   \n",
       "18                               Sociology    PG Taught           14088   \n",
       "19                              Statistics    PG Taught           23400   \n",
       "20                            Anthropology    PG Taught           16640   \n",
       "21                   International History    PG Taught           14088   \n",
       "\n",
       "    Overseas_fees_2019  \n",
       "0                19920  \n",
       "1                26358  \n",
       "2                21744  \n",
       "3                22870  \n",
       "4                21744  \n",
       "5                27870  \n",
       "6                21744  \n",
       "7                21744  \n",
       "8                24832  \n",
       "9                21744  \n",
       "10               22536  \n",
       "11               23328  \n",
       "12               24826  \n",
       "13               25176  \n",
       "14               21744  \n",
       "15               21744  \n",
       "16               21744  \n",
       "17               23570  \n",
       "18               21744  \n",
       "19               26320  \n",
       "20               21744  \n",
       "21               21744  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def extract_tables_from_pdf_2019(pdf_path_2019, output_csv_path_2019):\n",
    "    with pdfplumber.open(pdf_path_2019) as pdf_2019:\n",
    "        all_tables_2019 = []\n",
    "        for page_2019 in pdf_2019.pages:\n",
    "            tables_2019 = page_2019.extract_tables()\n",
    "            for table_2019 in tables_2019:\n",
    "                all_tables_2019.extend(table_2019)\n",
    "       \n",
    "        with open(output_csv_path_2019, 'w', newline='') as csvfile_2019:\n",
    "            writer_2019 = csv.writer(csvfile_2019)\n",
    "            for row_2019 in all_tables_2019:\n",
    "                writer_2019.writerow(row_2019)\n",
    "\n",
    "pdf_path_2019 = 'Data/2019-Table-of-Fees.pdf'\n",
    "output_csv_path_2019 = 'Data/2019_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf_2019(pdf_path_2019, output_csv_path_2019)\n",
    "\n",
    "output_csv_file_2019 = 'Data/2019_Fees.csv'  \n",
    "csv_file_2019 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "data_df_one_2019 = pd.read_csv(output_csv_file_2019, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2019 = pd.read_csv(csv_file_2019)\n",
    "\n",
    "data_df_one_2019['Dept_Program_2019'] = data_df_2019['Department'] + \" \" + data_df_2019['Program']\n",
    "\n",
    "unique_dept_programs_2019 = data_df_one_2019['Dept_Program_2019'].unique()\n",
    "\n",
    "original_to_transformed_2019 = {}\n",
    "processed_dept_programs_2019 = []\n",
    "for combo_2019 in unique_dept_programs_2019:\n",
    "    if isinstance(combo_2019, str):\n",
    "        if \"PG Taught\" in combo_2019:\n",
    "            original_department_2019 = combo_2019.replace(\" PG Taught\", \"\")\n",
    "            transformed_department_2019 = original_department_2019\n",
    "            if \"And\" in transformed_department_2019:\n",
    "                transformed_department_2019 = transformed_department_2019.split(\"And\")[0].strip()\n",
    "            if transformed_department_2019 == \"International History\":\n",
    "                transformed_department_2019 = \"History\"\n",
    "            if transformed_department_2019 == \"European Institute\":\n",
    "                transformed_department_2019 = \"European\"\n",
    "            if transformed_department_2019 == \"Law School\" or transformed_department_2019 == \"Law\":\n",
    "                transformed_department_2019 = \"LLM\"\n",
    "            if transformed_department_2019 == \"Philosophy Logic\":\n",
    "                transformed_department_2019 = \"Philosophy\"\n",
    "            if transformed_department_2019 == \"School of Public Policy\":\n",
    "                transformed_department_2019 = \"Public Policy\"\n",
    "            if transformed_department_2019 == \"Gender Studies\":\n",
    "                transformed_department_2019 = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department_2019:\n",
    "                transformed_department_2019 = \"Psychology\"\n",
    "            \n",
    "            original_to_transformed_2019[transformed_department_2019] = original_department_2019\n",
    "            processed_dept_programs_2019.append(transformed_department_2019)\n",
    "\n",
    "processed_df_2019 = pd.DataFrame(processed_dept_programs_2019, columns=['Department_2019'])\n",
    "\n",
    "processed_df_2019.insert(1, 'Program_2019', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2019(dept_program_2019):\n",
    "    matches_2019 = data_df_one_2019[data_df_one_2019.iloc[:, 0].str.contains(dept_program_2019, na=False)]\n",
    "    if not matches_2019.empty:\n",
    "        col2_values_2019 = []\n",
    "        col3_values_2019 = []\n",
    "        for _, row_2019 in matches_2019.iterrows():\n",
    "            try:\n",
    "                cleaned_value_col2_2019 = float(str(row_2019[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2_2019.is_integer():\n",
    "                    col2_values_2019.append(int(cleaned_value_col2_2019))\n",
    "            except ValueError:\n",
    "                col2_values_2019.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3_2019 = float(str(row_2019[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3_2019.is_integer():\n",
    "                    col3_values_2019.append(int(cleaned_value_col3_2019))\n",
    "            except ValueError:\n",
    "                col3_values_2019.append(pd.NA)\n",
    "        \n",
    "        avg_col2_2019 = pd.Series(col2_values_2019).dropna().mean()\n",
    "        avg_col3_2019 = pd.Series(col3_values_2019).dropna().mean()\n",
    "        return pd.Series([avg_col2_2019, avg_col3_2019])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "processed_df_2019[['Home_fees_2019', 'Overseas_fees_2019']] = processed_df_2019['Department_2019'].apply(find_matching_data_2019)\n",
    "\n",
    "processed_df_2019.dropna(subset=['Home_fees_2019', 'Overseas_fees_2019'], inplace=True)\n",
    "\n",
    "processed_df_2019['Home_fees_2019'] = processed_df_2019['Home_fees_2019'].astype(int)\n",
    "processed_df_2019['Overseas_fees_2019'] = processed_df_2019['Overseas_fees_2019'].astype(int)\n",
    "\n",
    "processed_df_2019['Department_2019'] = processed_df_2019['Department_2019'].map(original_to_transformed_2019)\n",
    "\n",
    "processed_df_2019\n",
    "\n",
    "idx_2019 = data_df_one_2019.index[data_df_one_2019.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2019:\n",
    "    target_idx_2019 = idx_2019[0]\n",
    "    if \"Undergraduate\" in data_df_one_2019.iloc[target_idx_2019 - 1, 0]:\n",
    "        year_match_2019 = re.search(r'\\b(\\d{4})\\b', data_df_one_2019.iloc[target_idx_2019, 0])\n",
    "        year_2019 = year_match_2019.group(0) if year_match_2019 else \"Unknown\"\n",
    "        home_fee_match_2019 = re.search(r'£(\\d{4})', data_df_one_2019.iloc[target_idx_2019, 1].replace(',', ''))\n",
    "        overseas_fee_match_2019 = re.search(r'£(\\d{5})', data_df_one_2019.iloc[target_idx_2019, 2].replace(',', ''))\n",
    "        home_fee_2019 = int(home_fee_match_2019.group(1)) if home_fee_match_2019 else None\n",
    "        overseas_fee_2019 = int(overseas_fee_match_2019.group(1)) if overseas_fee_match_2019 else None\n",
    "\n",
    "additional_row_2019 = pd.DataFrame({\n",
    "    'Department_2019': [\"All\"],\n",
    "    'Program_2019': [\"UG Degree\"],\n",
    "    'Home_fees_2019': [home_fee_2019],\n",
    "    'Overseas_fees_2019': [overseas_fee_2019]\n",
    "})\n",
    "\n",
    "processed_df_2019 = pd.concat([additional_row_2019, processed_df_2019]).reset_index(drop=True)\n",
    "\n",
    "processed_df_2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6efb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083cf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7361d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/470433332.py:29: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n",
      "/var/folders/w_/ccm86j116md1g5bmpdbhyv5r0000gn/T/ipykernel_70617/470433332.py:29: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'home_fee_2017' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 134\u001b[0m\n\u001b[1;32m    128\u001b[0m         overseas_fee_2017 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(overseas_fee_match_2017\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m overseas_fee_match_2017 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Add the extracted row to the top of the processed_df DataFrame\u001b[39;00m\n\u001b[1;32m    131\u001b[0m additional_row_2017 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgram\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUG Degree\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHome fees\u001b[39m\u001b[38;5;124m'\u001b[39m: [home_fee_2017],\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverseas fees\u001b[39m\u001b[38;5;124m'\u001b[39m: [overseas_fee_2017]\n\u001b[1;32m    136\u001b[0m })\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Append the additional row to the processed_df DataFrame\u001b[39;00m\n\u001b[1;32m    139\u001b[0m processed_df_2017 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([additional_row_2017, processed_df_2017])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'home_fee_2017' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_tables_from_pdf_2017(pdf_path_2017, output_csv_path_2017):\n",
    "    with pdfplumber.open(pdf_path_2017) as pdf_2017:\n",
    "        all_tables_2017 = []\n",
    "        # Iterate through each page of the PDF\n",
    "        for page_2017 in pdf_2017.pages:\n",
    "            # Extract tables from the current page\n",
    "            tables_2017 = page_2017.extract_tables()\n",
    "            for table_2017 in tables_2017:\n",
    "                all_tables_2017.extend(table_2017)  # Add the rows of the table to all_tables list\n",
    "       \n",
    "        # Write all extracted tables to a CSV file\n",
    "        with open(output_csv_path_2017, 'w', newline='') as csvfile_2017:\n",
    "            writer_2017 = csv.writer(csvfile_2017)\n",
    "            for row_2017 in all_tables_2017:\n",
    "                writer_2017.writerow(row_2017)\n",
    "\n",
    "# Specify the path to your PDF and the output CSV file\n",
    "pdf_path_2017 = 'Data/2017-18-Fees-Table.pdf'\n",
    "output_csv_path_2017 = 'Data/2017_Fees.csv'\n",
    "\n",
    "extract_tables_from_pdf_2017(pdf_path_2017, output_csv_path_2017)\n",
    "\n",
    "\n",
    "# Load the CSV file containing the tuition fees and program data\n",
    "output_csv_path_2017 = 'Data/2017_Fees.csv'  \n",
    "csv_path_2017 = 'Data/Florian_Wirtz_eigentlich_noch_was_mit_der_v2.csv'  \n",
    "\n",
    "# Read the CSV files\n",
    "data_df_one_2017 = pd.read_csv(output_csv_path_2017, error_bad_lines=False, warn_bad_lines=True)\n",
    "data_df_2017 = pd.read_csv(csv_path_2017)\n",
    "\n",
    "# Combine 'Department' and 'Program' into a new column for unique combinations\n",
    "data_df_2017['Dept_Program_2017'] = data_df_2017['Department'] + \" \" + data_df_2017['Program']\n",
    "\n",
    "# Get unique combinations\n",
    "unique_dept_programs_2017 = data_df_2017['Dept_Program_2017'].unique()\n",
    "\n",
    "# Dictionary to store original to transformed mappings\n",
    "original_to_transformed_2017 = {}\n",
    "\n",
    "# Process only Master's programs and adjust department names\n",
    "processed_dept_programs_2017 = []\n",
    "for combo_2017 in unique_dept_programs_2017:\n",
    "    if isinstance(combo_2017, str):  # Check if the item is a string\n",
    "        if \"PG Taught\" in combo_2017:\n",
    "            original_department_2017 = combo_2017.replace(\" PG Taught\", \"\")\n",
    "            transformed_department_2017 = original_department_2017\n",
    "            # Handle specific naming transformations\n",
    "            if \"And\" in transformed_department_2017:\n",
    "                transformed_department_2017 = transformed_department_2017.split(\"And\")[0].strip()\n",
    "            if transformed_department_2017 == \"International History\":\n",
    "                transformed_department_2017 = \"History\"\n",
    "            if transformed_department_2017 == \"European Institute\":\n",
    "                transformed_department_2017 = \"European\"\n",
    "            if transformed_department_2017 == \"Law School\" or transformed_department_2017 == \"Law\":\n",
    "                transformed_department_2017 = \"LLM\"\n",
    "            if transformed_department_2017 == \"Philosophy Logic\":\n",
    "                transformed_department_2017 = \"Philosophy\"\n",
    "            if transformed_department_2017 == \"School of Public Policy\":\n",
    "                transformed_department_2017 = \"Public Policy\"\n",
    "            if transformed_department_2017 == \"Gender Studies\":\n",
    "                transformed_department_2017 = \"Gender\"\n",
    "            if \"Psychological\" in transformed_department_2017:\n",
    "                transformed_department_2017 = \"Psychology\"\n",
    "            \n",
    "            # Save mapping\n",
    "            original_to_transformed_2017[transformed_department_2017] = original_department_2017\n",
    "            processed_dept_programs_2017.append(transformed_department_2017)\n",
    "\n",
    "# Create DataFrame from processed list\n",
    "processed_df_2017 = pd.DataFrame(processed_dept_programs_2017, columns=['Department'])\n",
    "\n",
    "# Insert \"Program\" column with \"PG Taught\" as the value for all entries\n",
    "processed_df_2017.insert(1, 'Program', 'PG Taught')\n",
    "\n",
    "def find_matching_data_2017(dept_program_2017):\n",
    "    matches_2017 = data_df_one_2017[data_df_one_2017.iloc[:, 0].str.contains(dept_program_2017, na=False)]\n",
    "    if not matches_2017.empty:\n",
    "        col2_values_2017 = []\n",
    "        col3_values_2017 = []\n",
    "        for _, row_2017 in matches_2017.iterrows():\n",
    "            # Process and clean fee data for averaging\n",
    "            try:\n",
    "                cleaned_value_col2_2017 = float(str(row_2017[1]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col2_2017.is_integer():\n",
    "                    col2_values_2017.append(int(cleaned_value_col2_2017))\n",
    "            except ValueError:\n",
    "                col2_values_2017.append(pd.NA)\n",
    "            try:\n",
    "                cleaned_value_col3_2017 = float(str(row_2017[2]).replace('£', '').replace(',', ''))\n",
    "                if cleaned_value_col3_2017.is_integer():\n",
    "                    col3_values_2017.append(int(cleaned_value_col3_2017))\n",
    "            except ValueError:\n",
    "                col3_values_2017.append(pd.NA)\n",
    "        \n",
    "        # Calculate averages while ignoring N/A values\n",
    "        avg_col2_2017 = pd.Series(col2_values_2017).dropna().mean()\n",
    "        avg_col3_2017 = pd.Series(col3_values_2017).dropna().mean()\n",
    "        return pd.Series([avg_col2_2017, avg_col3_2017])\n",
    "    return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "# Apply the function to find and average matching tuition fees\n",
    "processed_df_2017[['Home fees', 'Overseas fees']] = processed_df_2017['Department'].apply(find_matching_data_2017)\n",
    "\n",
    "# Remove rows where either column contains NA or NaN values\n",
    "processed_df_2017.dropna(subset=['Home fees', 'Overseas fees'], inplace=True)\n",
    "\n",
    "# Ensure all remaining values are integers\n",
    "processed_df_2017['Home fees'] = processed_df_2017['Home fees'].astype(int)\n",
    "processed_df_2017['Overseas fees'] = processed_df_2017['Overseas fees'].astype(int)\n",
    "\n",
    "# Revert department names to original values\n",
    "processed_df_2017['Department'] = processed_df_2017['Department'].map(original_to_transformed_2017)\n",
    "\n",
    "# Display the final DataFrame\n",
    "processed_df_2017\n",
    "\n",
    "# Find the row index for the specific phrase and extract the fees and year\n",
    "idx_2017 = data_df_one_2017.index[data_df_one_2017.iloc[:, 0].str.contains(\"Students commencing their degree in\" or \"New Entrants\", na=False)].tolist()\n",
    "if idx_2017:\n",
    "    target_idx_2017 = idx_2017[0]  # Assume the first occurrence\n",
    "    if \"Undergraduate\" in data_df_one_2017.iloc[target_idx_2017 - 1, 0]:\n",
    "        year_match_2017 = re.search(r'\\b(\\d{4})\\b', data_df_one_2017.iloc[target_idx_2017, 0])\n",
    "        year_2017 = year_match_2017.group(0) if year_match_2017 else \"Unknown\"\n",
    "        home_fee_match_2017 = re.search(r'£(\\d{4})', data_df_one_2017.iloc[target_idx_2017, 1].replace(',', ''))\n",
    "        overseas_fee_match_2017 = re.search(r'£(\\d{5})', data_df_one_2017.iloc[target_idx_2017, 2].replace(',', ''))\n",
    "        home_fee_2017 = int(home_fee_match_2017.group(1)) if home_fee_match_2017 else None\n",
    "        overseas_fee_2017 = int(overseas_fee_match_2017.group(1)) if overseas_fee_match_2017 else None\n",
    "\n",
    "# Add the extracted row to the top of the processed_df DataFrame\n",
    "additional_row_2017 = pd.DataFrame({\n",
    "    'Department': [\"All\"],\n",
    "    'Program': [\"UG Degree\"],\n",
    "    'Home fees': [home_fee_2017],\n",
    "    'Overseas fees': [overseas_fee_2017]\n",
    "})\n",
    "\n",
    "# Append the additional row to the processed_df DataFrame\n",
    "processed_df_2017 = pd.concat([additional_row_2017, processed_df_2017]).reset_index(drop=True)\n",
    "\n",
    "# Display the final DataFrame including the new row\n",
    "processed_df_2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all processed_df dataframes horizontally\n",
    "merged_df = pd.concat([processed_df_2017, processed_df_2018, processed_df_2019, processed_df_2020], axis=1)\n",
    "\n",
    "# Filter columns to keep only the first column and those without \"Program\" in their names\n",
    "columns_to_keep = [column for column in merged_df.columns if \"Program\" not in column or column == merged_df.columns[0]]\n",
    "\n",
    "# Select the filtered columns\n",
    "filtered_df = merged_df[columns_to_keep]\n",
    "\n",
    "# Filter columns to keep only the first column and those without \"Department\" in their names\n",
    "columns_to_keep_dept = [column for column in filtered_df.columns if \"Department\" not in column or column == filtered_df.columns[0]]\n",
    "\n",
    "# Select the filtered columns\n",
    "filtered_df_dept = filtered_df[columns_to_keep_dept]\n",
    "\n",
    "# Rename columns for Home and Overseas Fees with corresponding years\n",
    "filtered_df_dept.columns = [filtered_df_dept.columns[0].replace('_', ' ')] + \\\n",
    "                           [f\"{col.replace('_', ' ')} 2017\" if idx == 0 else f\"{col.replace('_', ' ')} 2017\" if idx == 1 else col.replace('_', ' ') for idx, col in enumerate(filtered_df_dept.columns[1:])]\n",
    "\n",
    "# Replace entry of the first department \"All 2017\" with simply \"All\"\n",
    "filtered_df_dept.iloc[0, 0] = \"All UG Degree\"\n",
    "\n",
    "# Display the renamed dataframe\n",
    "filtered_df_dept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f95e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([processed_df_2017, processed_df_2018, processed_df_2019, processed_df_2020], axis=1)\n",
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
