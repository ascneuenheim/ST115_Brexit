{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Read the original CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Data/table_v2.csv\")\n",
    "\n",
    "# Drop rows containing \"nationality\" in the first column\n",
    "df = df[~df.iloc[:, 0].str.contains('Nationality', na=False)]\n",
    "\n",
    "# Fill NaN values in the first column with the value from the row above\n",
    "df.iloc[:, 0] = df.iloc[:, 0].fillna(method='ffill')\n",
    "\n",
    "# Determine the number of columns in the original DataFrame\n",
    "num_columns_original = df.shape[1]\n",
    "\n",
    "# Define the new column names\n",
    "new_columns = ['Nationality', 'Department', 'Program',\n",
    "               'Applications 2019', 'Offers 2019', 'Entrances 2019',\n",
    "               'Applications 2020', 'Offers 2020', 'Entrances 2020',\n",
    "               'Applications 2021', 'Offers 2021', 'Entrances 2021',\n",
    "               'Applications 2022', 'Offers 2022', 'Entrances 2022']\n",
    "\n",
    "# Append empty columns to the new column names list if needed\n",
    "num_empty_columns = num_columns_original - len(new_columns)\n",
    "if num_empty_columns > 0:\n",
    "    new_columns += [''] * num_empty_columns\n",
    "\n",
    "# Rename the columns in the original DataFrame\n",
    "df.columns = new_columns\n",
    "\n",
    "df.to_csv(\"Data/GOKU_file_1.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40172a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the original and new CSV files\n",
    "input_file_path = \"Data/GOKU_file_1.csv\"\n",
    "output_file_path = \"Data/GOKU_file_2.csv\"\n",
    "\n",
    "# Open the original CSV file for reading and the new CSV file for writing\n",
    "with open(input_file_path, 'r') as infile, open(output_file_path, 'w') as outfile:\n",
    "    for line_number, line in enumerate(infile, start=1):\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split(',')\n",
    "        \n",
    "        # Check if the current line is within the rows to modify\n",
    "        if 873 <= line_number <= 923:\n",
    "            # Combine Column F with Column B (index 5 with index 1, considering 0-based indexing)\n",
    "            # Column F's entries come first\n",
    "            new_second_column = columns[5] + \" \" + columns[1]\n",
    "            columns[1] = new_second_column\n",
    "            # Move values from Column G (index 6) to Column F (index 5)\n",
    "            columns[5] = columns[6]\n",
    "            # Clear the old Column G\n",
    "            columns[6] = \"\"\n",
    "        \n",
    "        # Write the modified or unmodified line to the new CSV file\n",
    "        outfile.write(','.join(columns) + '\\n')\n",
    "\n",
    "# Load the updated CSV file into a DataFrame for inspection\n",
    "df_updated = pd.read_csv(output_file_path)\n",
    "\n",
    "# Display the modified rows for inspection\n",
    "df_updated.iloc[870:925]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d876d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the original and new CSV files\n",
    "input_file_path = \"Data/GOKU_file_2.csv\"\n",
    "output_file_path = \"Data/GOKU_file_3.csv\"\n",
    "\n",
    "# Open the original CSV file for reading and the new CSV file for writing\n",
    "with open(input_file_path, mode='r', newline='') as infile, open(output_file_path, mode='w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for line_number, row in enumerate(reader, start=1):\n",
    "        # Apply modifications only to specific rows\n",
    "        if 1543 <= line_number <= 1593:\n",
    "            row[1] = row[7] + \" \" + row[8]\n",
    "            row[7], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 1902 <= line_number <= 1952:\n",
    "            row[1] = row[9] + \" \" + row[8]\n",
    "            row[8], row[9] = \"\", \"\"\n",
    "\n",
    "        elif 2208 <= line_number <= 2258:\n",
    "            row[1] = row[7] + \" \" + row[8]\n",
    "            row[7], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 2566 <= line_number <= 2616:\n",
    "            row[1] = row[5] + \" \" + row[1]\n",
    "            row[5] = row[6]\n",
    "            row[6] = \"\"\n",
    "\n",
    "        elif 3995 <= line_number <= 4045:\n",
    "            row[1] = row[10] + \" \" + row[8]\n",
    "            row[10], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 4455 <= line_number <= 4505:\n",
    "            row[1] = row[10] + \" \" + row[8]\n",
    "            row[10], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 4813 <= line_number <= 4863:\n",
    "            row[1] = row[9] + \" \" + row[8]\n",
    "            row[9], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 5017 <= line_number <= 5067:\n",
    "            row[1] = row[7] + \" \" + row[8]\n",
    "            row[7], row[8] = \"\", \"\"\n",
    "\n",
    "        elif 5170 <= line_number <= 5220:\n",
    "            row[1] = row[9] + \" \" + row[8]\n",
    "            row[9], row[8] = \"\", \"\"\n",
    "\n",
    "        # Write the modified or unmodified row to the new CSV file\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Load the updated CSV file into a DataFrame for inspection\n",
    "df_updated = pd.read_csv(output_file_path)\n",
    "\n",
    "# Display the modified rows for inspection\n",
    "print(df_updated.iloc[1538:5225])  # Display a wider range around the modified areas for context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the file paths\n",
    "input_file = \"Data/GOKU_file_3.csv\"\n",
    "output_file = \"Data/GOKU_file_4.csv\"\n",
    "\n",
    "# Open the input CSV file for reading and the output CSV file for writing\n",
    "with open(input_file, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    # Create CSV reader and writer objects\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # Iterate through each row in the input CSV file\n",
    "    for row in reader:\n",
    "        # Split the row by space or comma to extract numbers and stars\n",
    "        values = ' '.join(row).split()\n",
    "        \n",
    "        # Extract numbers and stars from the values\n",
    "        numbers_stars = [value for value in values if value.isdigit() or value == '*']\n",
    "        \n",
    "        # Pad the numbers_stars list with NaNs to ensure it has 15 elements\n",
    "        numbers_stars.extend([''] * (15 - len(numbers_stars)))\n",
    "        \n",
    "        # Write the row with the numbers and stars distributed into the corresponding columns\n",
    "        writer.writerow(row[:3] + numbers_stars)\n",
    "        \n",
    "data = pd.read_csv(\"Data/GOKU_file_4.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "input_file = \"Data/GOKU_file_4.csv\"\n",
    "output_file = \"Data/GOKU_file_5.csv\"\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "data = pd.read_csv(input_file)\n",
    "\n",
    "# Remove all entries from the \"Program\" column\n",
    "data['Program'] = \" \"\n",
    "\n",
    "# Remove all numbers and asterisks from the \"Department\" column\n",
    "data['Department'] = data['Department'].str.replace(r'[\\d\\*]+', '', regex=True)\n",
    "\n",
    "# Use regex to extract \"UG Degree\" or \"PG Taught\" and the remaining department part\n",
    "data['Program'] = data['Department'].str.extract('(UG Degree|PG Taught)')\n",
    "data['Department'] = data['Department'].str.replace('UG Degree|PG Taught', '').str.strip()\n",
    "\n",
    "prev_program = None  # To store the 'Programme' of the previous row\n",
    "prev_index = None      # To store the index of the previous row\n",
    "\n",
    "# Iterate over the DataFrame using .iterrows()\n",
    "for index, row in data.iterrows():\n",
    "    if prev_program == 'UG Degree' and row['Program'] == 'PG Taught' and row['Department'].strip():\n",
    "        # Concatenate the department name from the current row to the previous row\n",
    "        data.at[prev_index, 'Department'] += ' ' + row['Department']\n",
    "        # Clear the department in the current row\n",
    "        data.at[index, 'Department'] = ''\n",
    "    \n",
    "    # Update previous row info\n",
    "    prev_program = row['Program']\n",
    "    prev_index = index\n",
    "    \n",
    "# Fill forwards to have no empty rows\n",
    "data['Department'] = data['Department'].replace('', pd.NA).fillna(method='ffill')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    if row['Department'] == \"European In..\":\n",
    "        data.at[index, 'Department'] = \"European Institute\"\n",
    "    elif row['Department'] == \"Gender Stud..\":\n",
    "        data.at[index, 'Department'] = \"Gender Studies\"\n",
    "    elif row['Department'] == \"Geography and Environ..\":\n",
    "        data.at[index, 'Department'] = \"Geography and Environment\"\n",
    "    elif row['Department'] == \"International..\":\n",
    "        data.at[index, 'Department'] = \"International Development\"\n",
    "    elif row['Department'] == \"Media and C..\":\n",
    "        data.at[index, 'Department'] = \"Media and Communications\"\n",
    "    elif row['Department'] == \"Philosophy, Logic and S..\":\n",
    "        data.at[index, 'Department'] = \"Philosophy, Logic and Scientific Method\"\n",
    "    elif row['Department'] == \"Psychologic..\":\n",
    "        data.at[index, 'Department'] = \"Psychological and Behavioural Sciences\"\n",
    "    elif row['Department'] == \"School of Pu..\":\n",
    "        data.at[index, 'Department'] = \"School of Public Policy\"\n",
    "        \n",
    "\n",
    "\n",
    "new_columns = ['Nationality', 'Department', 'Program',\n",
    "               'Applications 2019', 'Offers 2019', 'Entrances 2019',\n",
    "               'Applications 2020', 'Offers 2020', 'Entrances 2020',\n",
    "               'Applications 2021', 'Offers 2021', 'Entrances 2021',\n",
    "               'Applications 2022', 'Offers 2022', 'Entrances 2022',\n",
    "               'Applications 2023', 'Offers 2023', 'Entrances 2023']\n",
    "data.columns = new_columns\n",
    "\n",
    "# Save the modified DataFrame to the new output CSV file\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the modified data\n",
    "data = pd.read_csv(output_file)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
